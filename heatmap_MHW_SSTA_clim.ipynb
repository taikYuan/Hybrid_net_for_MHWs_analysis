{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d11fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    A set of functions which implement the Marine Heat Wave (MHW)\n",
    "    definition of Hobday et al. (2016)\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg\n",
    "from scipy import stats\n",
    "import scipy.ndimage as ndimage\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "def detect(t, temp, climatologyPeriod=[None,None], pctile=90, windowHalfWidth=5, smoothPercentile=True, smoothPercentileWidth=31, minDuration=5, joinAcrossGaps=True, maxGap=2, maxPadLength=False, coldSpells=False, alternateClimatology=False, Ly=False):\n",
    "    '''\n",
    "    Applies the Hobday et al. (2016) marine heat wave definition to an input time\n",
    "    series of temp ('temp') along with a time vector ('t'). Outputs properties of\n",
    "    all detected marine heat waves.\n",
    "    Inputs:\n",
    "      t       Time vector, in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "              [1D numpy array of length T]\n",
    "      temp    Temperature vector [1D numpy array of length T]\n",
    "    Outputs:\n",
    "      mhw     Detected marine heat waves (MHWs). Each key (following list) is a\n",
    "              list of length N where N is the number of detected MHWs:\n",
    " \n",
    "        'time_start'           Start time of MHW [datetime format] # MHW开始的时间\n",
    "        'time_end'             End time of MHW [datetime format]  # MHW结束的时间\n",
    "        'time_peak'            Time of MHW peak [datetime format] # MHW的峰值时间\n",
    "        'date_start'           Start date of MHW [datetime format]  # MHW开始的日期\n",
    "        'date_end'             End date of MHW [datetime format]   # MHW结束的日期\n",
    "        'date_peak'            Date of MHW peak [datetime format] # MHW峰值的时间\n",
    "        'index_start'          Start index of MHW #MHW开始的索引\n",
    "        'index_end'            End index of MHW  #MHW结束的索引\n",
    "        'index_peak'           Index of MHW peak #MHW峰值的索引\n",
    "        'duration'             Duration of MHW [days] #MHW经历的日期\n",
    "        'intensity_max'        Maximum (peak) intensity [deg. C]  # 最大强度\n",
    "        'intensity_mean'       Mean intensity [deg. C] #平均强度\n",
    "        'intensity_var'        Intensity variability [deg. C] # \n",
    "        'intensity_cumulative' Cumulative intensity [deg. C x days] #累积强度\n",
    "        'rate_onset'           Onset rate of MHW [deg. C / days] # MHW的增长率\n",
    "        'rate_decline'         Decline rate of MHW [deg. C / days]\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "        'category' is an integer category system (1, 2, 3, 4) based on the maximum intensity\n",
    "        in multiples of threshold exceedances, i.e., a value of 1 indicates the MHW\n",
    "        intensity (relative to the climatology) was >=1 times the value of the threshold (but\n",
    "        less than 2 times; relative to climatology, i.e., threshold - climatology).\n",
    "        Category types are defined as 1=moderate, 2=strong, 3=severe, 4=extreme. More details in\n",
    "        Hobday et al. (in prep., Oceanography). Also supplied are the duration of each of these\n",
    "        categories for each event.  #这些相对于阈值而不是相对于气候态\n",
    "        'n_events'             A scalar integer (not a list) indicating the total\n",
    "                               number of detected MHW events  # 发生了几次MHW事件\n",
    "      clim    Climatology of SST. Each key (following list) is a seasonally-varying\n",
    "              time series [1D numpy array of length T] of a particular measure:  # 海温的气候学\n",
    "        'thresh'               Seasonally varying threshold (e.g., 90th percentile) # 季节性变化的阈值 （例如 90百分位数）\n",
    "        'seas'                 Climatological seasonal cycle  # 气候季节循环\n",
    "        'missing'              A vector of TRUE/FALSE indicating which elements in \n",
    "                               temp were missing values for the MHWs detection\n",
    "    Options:\n",
    "      climatologyPeriod      Period over which climatology is calculated, specified\n",
    "                             as list of start and end years. Default is to calculate\n",
    "                             over the full range of years in the supplied time series.\n",
    "                             Alternate periods suppled as a list e.g. [1983,2012].\n",
    "      pctile                 Threshold percentile (%) for detection of extreme values\n",
    "                             (DEFAULT = 90)\n",
    "      windowHalfWidth        Width of window (one sided) about day-of-year used for\n",
    "                             the pooling of values and calculation of threshold percentile\n",
    "                             (DEFAULT = 5 [days])\n",
    "      smoothPercentile       Boolean switch indicating whether to smooth the threshold\n",
    "                             percentile timeseries with a moving average (DEFAULT = True)\n",
    "      smoothPercentileWidth  Width of moving average window for smoothing threshold\n",
    "                             (DEFAULT = 31 [days])\n",
    "      minDuration            Minimum duration for acceptance detected MHWs\n",
    "                             (DEFAULT = 5 [days])\n",
    "      joinAcrossGaps         Boolean switch indicating whether to join MHWs\n",
    "                             which occur before/after a short gap (DEFAULT = True)\n",
    "      maxGap                 Maximum length of gap allowed for the joining of MHWs\n",
    "                             (DEFAULT = 2 [days])\n",
    "      maxPadLength           Specifies the maximum length [days] over which to interpolate\n",
    "                             (pad) missing data (specified as nans) in input temp time series.\n",
    "                             i.e., any consecutive blocks of NaNs with length greater\n",
    "                             than maxPadLength will be left as NaN. Set as an integer.\n",
    "                             (DEFAULT = False, interpolates over all missing values).\n",
    "      coldSpells             Specifies if the code should detect cold events instead of\n",
    "                             heat events. (DEFAULT = False)\n",
    "      alternateClimatology   Specifies an alternate temperature time series to use for the\n",
    "                             calculation of the climatology. Format is as a list of numpy\n",
    "                             arrays: (1) the first element of the list is a time vector,\n",
    "                             in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "                             [1D numpy array of length TClim] and (2) the second element of\n",
    "                             the list is a temperature vector [1D numpy array of length TClim].\n",
    "                             (DEFAULT = False)\n",
    "      Ly                     Specifies if the length of the year is < 365/366 days (e.g. a \n",
    "                             360 day year from a climate model). This affects the calculation\n",
    "                             of the climatology. (DEFAULT = False)\n",
    "    Notes:\n",
    "      1. This function assumes that the input time series consist of continuous daily values\n",
    "         with few missing values. Time ranges which start and end part-way through the calendar\n",
    "         year are supported.\n",
    "      2. This function supports leap years. This is done by ignoring Feb 29s for the initial\n",
    "         calculation of the climatology and threshold. The value of these for Feb 29 is then\n",
    "         linearly interpolated from the values for Feb 28 and Mar 1.\n",
    "      3. The calculation of onset and decline rates assumes that the heat wave started a half-day\n",
    "         before the start day and ended a half-day after the end-day. (This is consistent with the\n",
    "         duration definition as implemented, which assumes duration = end day - start day + 1.)\n",
    "      4. For the purposes of MHW detection, any missing temp values not interpolated over (through\n",
    "         optional maxPadLLength) will be set equal to the seasonal climatology. This means they will\n",
    "         trigger the end/start of any adjacent temp values which satisfy the MHW criteria.\n",
    "      5. If the code is used to detect cold events (coldSpells = True), then it works just as for heat\n",
    "         waves except that events are detected as deviations below the (100 - pctile)th percentile\n",
    "         (e.g., the 10th instead of 90th) for at least 5 days. Intensities are reported as negative\n",
    "         values and represent the temperature anomaly below climatology.\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb 2015\n",
    "    '''\n",
    "\n",
    "    #\n",
    "    # Initialize MHW output variable\n",
    "    #\n",
    "\n",
    "    mhw = {}\n",
    "    mhw['time_start'] = [] # datetime format\n",
    "    mhw['time_end'] = [] # datetime format\n",
    "    mhw['time_peak'] = [] # datetime format\n",
    "    mhw['date_start'] = [] # datetime format\n",
    "    mhw['date_end'] = [] # datetime format\n",
    "    mhw['date_peak'] = [] # datetime format\n",
    "    mhw['index_start'] = []\n",
    "    mhw['index_end'] = []\n",
    "    mhw['index_peak'] = []\n",
    "    mhw['duration'] = [] # [days]\n",
    "    mhw['duration_moderate'] = [] # [days]\n",
    "    mhw['duration_strong'] = [] # [days]\n",
    "    mhw['duration_severe'] = [] # [days]\n",
    "    mhw['duration_extreme'] = [] # [days]\n",
    "    mhw['intensity_max'] = [] # [deg C]\n",
    "    mhw['intensity_mean'] = [] # [deg C]\n",
    "    mhw['intensity_var'] = [] # [deg C]\n",
    "    mhw['intensity_cumulative'] = [] # [deg C]\n",
    "    mhw['intensity_max_relThresh'] = [] # [deg C]\n",
    "    mhw['intensity_mean_relThresh'] = [] # [deg C]\n",
    "    mhw['intensity_var_relThresh'] = [] # [deg C]\n",
    "    mhw['intensity_cumulative_relThresh'] = [] # [deg C]\n",
    "    mhw['intensity_max_abs'] = [] # [deg C]\n",
    "    mhw['intensity_mean_abs'] = [] # [deg C]\n",
    "    mhw['intensity_var_abs'] = [] # [deg C]\n",
    "    mhw['intensity_cumulative_abs'] = [] # [deg C]\n",
    "    mhw['category'] = []\n",
    "    mhw['rate_onset'] = [] # [deg C / day]\n",
    "    mhw['rate_decline'] = [] # [deg C / day]\n",
    "\n",
    "    #\n",
    "    # Time and dates vectors\n",
    "    #\n",
    "\n",
    "    # Generate vectors for year, month, day-of-month, and day-of-year\n",
    "    T = len(t)\n",
    "    year = np.zeros((T))\n",
    "    month = np.zeros((T))\n",
    "    day = np.zeros((T))\n",
    "    doy = np.zeros((T))\n",
    "    for i in range(T):\n",
    "        year[i] = date.fromordinal(t[i]).year\n",
    "        month[i] = date.fromordinal(t[i]).month\n",
    "        day[i] = date.fromordinal(t[i]).day\n",
    "    # Leap-year baseline for defining day-of-year values\n",
    "    year_leapYear = 2012 # This year was a leap-year and therefore doy in range of 1 to 366\n",
    "    t_leapYear = np.arange(date(year_leapYear, 1, 1).toordinal(),date(year_leapYear, 12, 31).toordinal()+1)\n",
    "    dates_leapYear = [date.fromordinal(tt.astype(int)) for tt in t_leapYear]\n",
    "    month_leapYear = np.zeros((len(t_leapYear)))\n",
    "    day_leapYear = np.zeros((len(t_leapYear)))\n",
    "    doy_leapYear = np.zeros((len(t_leapYear)))\n",
    "    for tt in range(len(t_leapYear)):\n",
    "        month_leapYear[tt] = date.fromordinal(t_leapYear[tt]).month\n",
    "        day_leapYear[tt] = date.fromordinal(t_leapYear[tt]).day\n",
    "        doy_leapYear[tt] = t_leapYear[tt] - date(date.fromordinal(t_leapYear[tt]).year,1,1).toordinal() + 1\n",
    "        \n",
    "    # Calculate day-of-year values\n",
    "    for tt in range(T):\n",
    "        doy[tt] = doy_leapYear[(month_leapYear == month[tt]) * (day_leapYear == day[tt])]\n",
    "\n",
    "    # Constants (doy values for Feb-28 and Feb-29) for handling leap-years\n",
    "    feb28 = 59\n",
    "    feb29 = 60\n",
    "\n",
    "    # Set climatology period, if unset use full range of available data\n",
    "    if (climatologyPeriod[0] is None) or (climatologyPeriod[1] is None):\n",
    "        climatologyPeriod[0] = year[0]\n",
    "        climatologyPeriod[1] = year[-1]\n",
    "\n",
    "    #\n",
    "    # Calculate threshold and seasonal climatology (varying with day-of-year)\n",
    "    #\n",
    "\n",
    "    # if alternate temperature time series is supplied for the calculation of the climatology\n",
    "    if alternateClimatology:\n",
    "        tClim = alternateClimatology[0]\n",
    "        tempClim = alternateClimatology[1]\n",
    "        TClim = len(tClim)\n",
    "        yearClim = np.zeros((TClim))\n",
    "        monthClim = np.zeros((TClim))\n",
    "        dayClim = np.zeros((TClim))\n",
    "        doyClim = np.zeros((TClim))\n",
    "        for i in range(TClim):\n",
    "            yearClim[i] = date.fromordinal(tClim[i]).year\n",
    "            monthClim[i] = date.fromordinal(tClim[i]).month\n",
    "            dayClim[i] = date.fromordinal(tClim[i]).day\n",
    "            doyClim[i] = doy_leapYear[(month_leapYear == monthClim[i]) * (day_leapYear == dayClim[i])]\n",
    "    else:\n",
    "        tempClim = temp.copy()\n",
    "        TClim = np.array([T]).copy()[0]\n",
    "        yearClim = year.copy()\n",
    "        monthClim = month.copy()\n",
    "        dayClim = day.copy()\n",
    "        doyClim = doy.copy()\n",
    "\n",
    "    # Flip temp time series if detecting cold spells\n",
    "    if coldSpells:\n",
    "        temp = -1.*temp\n",
    "        tempClim = -1.*tempClim\n",
    "\n",
    "    # Pad missing values for all consecutive missing blocks of length <= maxPadLength\n",
    "    if maxPadLength:\n",
    "        temp = pad(temp, maxPadLength=maxPadLength)\n",
    "        tempClim = pad(tempClim, maxPadLength=maxPadLength)\n",
    "\n",
    "    # Length of climatological year\n",
    "    lenClimYear = 366\n",
    "    # Start and end indices\n",
    "    clim_start = np.where(yearClim == climatologyPeriod[0])[0][0]\n",
    "    clim_end = np.where(yearClim == climatologyPeriod[1])[0][-1]\n",
    "    # Inialize arrays\n",
    "    thresh_climYear = np.NaN*np.zeros(lenClimYear)\n",
    "    seas_climYear = np.NaN*np.zeros(lenClimYear)\n",
    "    clim = {}\n",
    "    clim['thresh'] = np.NaN*np.zeros(TClim)\n",
    "    clim['seas'] = np.NaN*np.zeros(TClim)\n",
    "    # Loop over all day-of-year values, and calculate threshold and seasonal climatology across years\n",
    "    for d in range(1,lenClimYear+1):\n",
    "        # Special case for Feb 29\n",
    "        if d == feb29:\n",
    "            continue\n",
    "        # find all indices for each day of the year +/- windowHalfWidth and from them calculate the threshold\n",
    "        tt0 = np.where(doyClim[clim_start:clim_end+1] == d)[0] \n",
    "        # If this doy value does not exist (i.e. in 360-day calendars) then skip it\n",
    "        if len(tt0) == 0:\n",
    "            continue\n",
    "        tt = np.array([])\n",
    "        for w in range(-windowHalfWidth, windowHalfWidth+1):\n",
    "            tt = np.append(tt, clim_start+tt0 + w)\n",
    "        tt = tt[tt>=0] # Reject indices \"before\" the first element\n",
    "        tt = tt[tt<TClim] # Reject indices \"after\" the last element\n",
    "        thresh_climYear[d-1] = np.nanpercentile(tempClim[tt.astype(int)], pctile)\n",
    "        seas_climYear[d-1] = np.nanmean(tempClim[tt.astype(int)])\n",
    "    # Special case for Feb 29\n",
    "    thresh_climYear[feb29-1] = 0.5*thresh_climYear[feb29-2] + 0.5*thresh_climYear[feb29]\n",
    "    seas_climYear[feb29-1] = 0.5*seas_climYear[feb29-2] + 0.5*seas_climYear[feb29]\n",
    "\n",
    "    # Smooth if desired\n",
    "    if smoothPercentile:\n",
    "        # If the length of year is < 365/366 (e.g. a 360 day year from a Climate Model)\n",
    "        if Ly:\n",
    "            valid = ~np.isnan(thresh_climYear)\n",
    "            thresh_climYear[valid] = runavg(thresh_climYear[valid], smoothPercentileWidth)\n",
    "            valid = ~np.isnan(seas_climYear)\n",
    "            seas_climYear[valid] = runavg(seas_climYear[valid], smoothPercentileWidth)\n",
    "        # >= 365-day year\n",
    "        else:\n",
    "            thresh_climYear = runavg(thresh_climYear, smoothPercentileWidth)\n",
    "            seas_climYear = runavg(seas_climYear, smoothPercentileWidth)\n",
    "\n",
    "    # Generate threshold for full time series\n",
    "    clim['thresh'] = thresh_climYear[doy.astype(int)-1]\n",
    "    clim['seas'] = seas_climYear[doy.astype(int)-1]\n",
    "\n",
    "    # Save vector indicating which points in temp are missing values\n",
    "    clim['missing'] = np.isnan(temp)\n",
    "    # Set all remaining missing temp values equal to the climatology\n",
    "    temp[np.isnan(temp)] = clim['seas'][np.isnan(temp)]\n",
    "\n",
    "    #\n",
    "    # Find MHWs as exceedances above the threshold\n",
    "    #\n",
    "\n",
    "    # Time series of \"True\" when threshold is exceeded, \"False\" otherwise\n",
    "    exceed_bool = temp - clim['thresh']\n",
    "    exceed_bool[exceed_bool<=0] = False\n",
    "    exceed_bool[exceed_bool>0] = True\n",
    "    # Fix issue where missing temp vaues (nan) are counted as True\n",
    "    exceed_bool[np.isnan(exceed_bool)] = False\n",
    "    # Find contiguous regions of exceed_bool = True\n",
    "    events, n_events = ndimage.label(exceed_bool)\n",
    "\n",
    "    # Find all MHW events of duration >= minDuration\n",
    "    for ev in range(1,n_events+1):\n",
    "        event_duration = (events == ev).sum()\n",
    "        if event_duration < minDuration:\n",
    "            continue\n",
    "        mhw['time_start'].append(t[np.where(events == ev)[0][0]])\n",
    "        mhw['time_end'].append(t[np.where(events == ev)[0][-1]])\n",
    "\n",
    "    # Link heat waves that occur before and after a short gap (gap must be no longer than maxGap)\n",
    "    if joinAcrossGaps:\n",
    "        # Calculate gap length for each consecutive pair of events\n",
    "        gaps = np.array(mhw['time_start'][1:]) - np.array(mhw['time_end'][0:-1]) - 1\n",
    "        if len(gaps) > 0:\n",
    "            while gaps.min() <= maxGap:\n",
    "                # Find first short gap\n",
    "                ev = np.where(gaps <= maxGap)[0][0]\n",
    "                # Extend first MHW to encompass second MHW (including gap)\n",
    "                mhw['time_end'][ev] = mhw['time_end'][ev+1]\n",
    "                # Remove second event from record\n",
    "                del mhw['time_start'][ev+1]\n",
    "                del mhw['time_end'][ev+1]\n",
    "                # Calculate gap length for each consecutive pair of events\n",
    "                gaps = np.array(mhw['time_start'][1:]) - np.array(mhw['time_end'][0:-1]) - 1\n",
    "                if len(gaps) == 0:\n",
    "                    break\n",
    "\n",
    "    # Calculate marine heat wave properties\n",
    "    mhw['n_events'] = len(mhw['time_start'])\n",
    "    categories = np.array(['Moderate', 'Strong', 'Severe', 'Extreme'])\n",
    "    for ev in range(mhw['n_events']):\n",
    "        mhw['date_start'].append(date.fromordinal(mhw['time_start'][ev]))\n",
    "        mhw['date_end'].append(date.fromordinal(mhw['time_end'][ev]))\n",
    "        # Get SST series during MHW event, relative to both threshold and to seasonal climatology\n",
    "        tt_start = np.where(t==mhw['time_start'][ev])[0][0]\n",
    "        tt_end = np.where(t==mhw['time_end'][ev])[0][0]\n",
    "        mhw['index_start'].append(tt_start)\n",
    "        mhw['index_end'].append(tt_end)\n",
    "        temp_mhw = temp[tt_start:tt_end+1]\n",
    "        thresh_mhw = clim['thresh'][tt_start:tt_end+1]\n",
    "        seas_mhw = clim['seas'][tt_start:tt_end+1]\n",
    "        mhw_relSeas = temp_mhw - seas_mhw\n",
    "        mhw_relThresh = temp_mhw - thresh_mhw\n",
    "        mhw_relThreshNorm = (temp_mhw - thresh_mhw) / (thresh_mhw - seas_mhw)\n",
    "        mhw_abs = temp_mhw\n",
    "        # Find peak\n",
    "        tt_peak = np.argmax(mhw_relSeas)\n",
    "        mhw['time_peak'].append(mhw['time_start'][ev] + tt_peak)\n",
    "        mhw['date_peak'].append(date.fromordinal(mhw['time_start'][ev] + tt_peak))\n",
    "        mhw['index_peak'].append(tt_start + tt_peak)\n",
    "        # MHW Duration\n",
    "        mhw['duration'].append(len(mhw_relSeas))\n",
    "        # MHW Intensity metrics\n",
    "        mhw['intensity_max'].append(mhw_relSeas[tt_peak])\n",
    "        mhw['intensity_mean'].append(mhw_relSeas.mean())\n",
    "        mhw['intensity_var'].append(np.sqrt(mhw_relSeas.var()))\n",
    "        mhw['intensity_cumulative'].append(mhw_relSeas.sum())\n",
    "        mhw['intensity_max_relThresh'].append(mhw_relThresh[tt_peak])\n",
    "        mhw['intensity_mean_relThresh'].append(mhw_relThresh.mean())\n",
    "        mhw['intensity_var_relThresh'].append(np.sqrt(mhw_relThresh.var()))\n",
    "        mhw['intensity_cumulative_relThresh'].append(mhw_relThresh.sum())\n",
    "        mhw['intensity_max_abs'].append(mhw_abs[tt_peak])\n",
    "        mhw['intensity_mean_abs'].append(mhw_abs.mean())\n",
    "        mhw['intensity_var_abs'].append(np.sqrt(mhw_abs.var()))\n",
    "        mhw['intensity_cumulative_abs'].append(mhw_abs.sum())\n",
    "        # Fix categories\n",
    "        tt_peakCat = np.argmax(mhw_relThreshNorm)\n",
    "        cats = np.floor(1. + mhw_relThreshNorm)\n",
    "        mhw['category'].append(categories[np.min([cats[tt_peakCat], 4]).astype(int) - 1])\n",
    "        mhw['duration_moderate'].append(np.sum(cats == 1.))\n",
    "        mhw['duration_strong'].append(np.sum(cats == 2.))\n",
    "        mhw['duration_severe'].append(np.sum(cats == 3.))\n",
    "        mhw['duration_extreme'].append(np.sum(cats >= 4.))\n",
    "        \n",
    "        # Rates of onset and decline\n",
    "        # Requires getting MHW strength at \"start\" and \"end\" of event (continuous: assume start/end half-day before/after first/last point)\n",
    "        if tt_start > 0:\n",
    "            mhw_relSeas_start = 0.5*(mhw_relSeas[0] + temp[tt_start-1] - clim['seas'][tt_start-1])\n",
    "            mhw['rate_onset'].append((mhw_relSeas[tt_peak] - mhw_relSeas_start) / (tt_peak+0.5))\n",
    "        else: # MHW starts at beginning of time series\n",
    "            if tt_peak == 0: # Peak is also at begining of time series, assume onset time = 1 day\n",
    "                mhw['rate_onset'].append((mhw_relSeas[tt_peak] - mhw_relSeas[0]) / 1.)\n",
    "            else:\n",
    "                mhw['rate_onset'].append((mhw_relSeas[tt_peak] - mhw_relSeas[0]) / tt_peak)\n",
    "        if tt_end < T-1:\n",
    "            mhw_relSeas_end = 0.5*(mhw_relSeas[-1] + temp[tt_end+1] - clim['seas'][tt_end+1])\n",
    "            mhw['rate_decline'].append((mhw_relSeas[tt_peak] - mhw_relSeas_end) / (tt_end-tt_start-tt_peak+0.5))\n",
    "        else: # MHW finishes at end of time series\n",
    "            if tt_peak == T-1: # Peak is also at end of time series, assume decline time = 1 day\n",
    "                mhw['rate_decline'].append((mhw_relSeas[tt_peak] - mhw_relSeas[-1]) / 1.)\n",
    "            else:\n",
    "                mhw['rate_decline'].append((mhw_relSeas[tt_peak] - mhw_relSeas[-1]) / (tt_end-tt_start-tt_peak))\n",
    "\n",
    "    # Flip climatology and intensties in case of cold spell detection\n",
    "    if coldSpells:\n",
    "        clim['seas'] = -1.*clim['seas']\n",
    "        clim['thresh'] = -1.*clim['thresh']\n",
    "        for ev in range(len(mhw['intensity_max'])):\n",
    "            mhw['intensity_max'][ev] = -1.*mhw['intensity_max'][ev]\n",
    "            mhw['intensity_mean'][ev] = -1.*mhw['intensity_mean'][ev]\n",
    "            mhw['intensity_cumulative'][ev] = -1.*mhw['intensity_cumulative'][ev]\n",
    "            mhw['intensity_max_relThresh'][ev] = -1.*mhw['intensity_max_relThresh'][ev]\n",
    "            mhw['intensity_mean_relThresh'][ev] = -1.*mhw['intensity_mean_relThresh'][ev]\n",
    "            mhw['intensity_cumulative_relThresh'][ev] = -1.*mhw['intensity_cumulative_relThresh'][ev]\n",
    "            mhw['intensity_max_abs'][ev] = -1.*mhw['intensity_max_abs'][ev]\n",
    "            mhw['intensity_mean_abs'][ev] = -1.*mhw['intensity_mean_abs'][ev]\n",
    "            mhw['intensity_cumulative_abs'][ev] = -1.*mhw['intensity_cumulative_abs'][ev]\n",
    "\n",
    "    return mhw, clim\n",
    "\n",
    "\n",
    "def blockAverage(t, mhw, clim=None, blockLength=1, removeMissing=False, temp=None):\n",
    "    '''\n",
    "    Calculate statistics of marine heatwave (MHW) properties averaged over blocks of\n",
    "    a specified length of time. Takes as input a collection of detected MHWs\n",
    "    (using the marineHeatWaves.detect function) and a time vector for the source\n",
    "    SST series.\n",
    "    Inputs:\n",
    "      t       Time vector, in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "      mhw     Marine heat waves (MHWs) detected using marineHeatWaves.detect\n",
    "    Outputs:\n",
    "      mhwBlock   Time series of block-averaged MHW properties. Each key (following list)\n",
    "                 is a list of length N where N is the number of blocks:\n",
    " \n",
    "        'years_start'          Start year blocks (inclusive)\n",
    "        'years_end'            End year of blocks (inclusive)\n",
    "        'years_centre'         Decimal year at centre of blocks\n",
    "        'count'                Total MHW count in each block\n",
    "        'duration'             Average MHW duration in each block [days]\n",
    "        'intensity_max'        Average MHW \"maximum (peak) intensity\" in each block [deg. C]\n",
    "        'intensity_max_max'    Maximum MHW \"maximum (peak) intensity\" in each block [deg. C]\n",
    "        'intensity_mean'       Average MHW \"mean intensity\" in each block [deg. C]\n",
    "        'intensity_var'        Average MHW \"intensity variability\" in each block [deg. C]\n",
    "        'intensity_cumulative' Average MHW \"cumulative intensity\" in each block [deg. C x days]\n",
    "        'rate_onset'           Average MHW onset rate in each block [deg. C / days]\n",
    "        'rate_decline'         Average MHW decline rate in each block [deg. C / days]\n",
    "        'total_days'           Total number of MHW days in each block [days]\n",
    "        'total_icum'           Total cumulative intensity over all MHWs in each block [deg. C x days]\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "    Options:\n",
    "      blockLength            Size of block (in years) over which to calculate the\n",
    "                             averaged MHW properties. Must be an integer greater than\n",
    "                             or equal to 1 (DEFAULT = 1 [year])\n",
    "      removeMissing          Boolean switch indicating whether to remove (set = NaN)\n",
    "                             statistics for any blocks in which there were missing \n",
    "                             temperature values (DEFAULT = FALSE)\n",
    "      clim                   The temperature climatology (including missing value information)\n",
    "                             as output by marineHeatWaves.detect (required if removeMissing = TRUE)\n",
    "      temp                   Temperature time series. If included mhwBlock will output block\n",
    "                             averages of mean, max, and min temperature (DEFAULT = NONE)\n",
    "                             If both clim and temp are provided, this will output annual counts\n",
    "                             of moderate, strong, severe, and extreme days.\n",
    "    Notes:\n",
    "      This function assumes that the input time vector consists of continuous daily values. Note that\n",
    "      in the case of time ranges which start and end part-way through the calendar year, the block\n",
    "      averages at the endpoints, for which there is less than a block length of data, will need to be\n",
    "      interpreted with care.\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb-Mar 2015\n",
    "    '''\n",
    "\n",
    "    #\n",
    "    # Time and dates vectors, and calculate block timing\n",
    "    #\n",
    "\n",
    "    # Generate vectors for year, month, day-of-month, and day-of-year\n",
    "    T = len(t)\n",
    "    year = np.zeros((T))\n",
    "    month = np.zeros((T))\n",
    "    day = np.zeros((T))\n",
    "    for i in range(T):\n",
    "        year[i] = date.fromordinal(t[i]).year\n",
    "        month[i] = date.fromordinal(t[i]).month\n",
    "        day[i] = date.fromordinal(t[i]).day\n",
    "\n",
    "    # Number of blocks, round up to include partial blocks at end\n",
    "    years = np.unique(year)\n",
    "    nBlocks = np.ceil((years.max() - years.min() + 1) / blockLength).astype(int)\n",
    "\n",
    "    #\n",
    "    # Temperature time series included?\n",
    "    #\n",
    "\n",
    "    sw_temp = None\n",
    "    sw_cats = None\n",
    "    if temp is not None:\n",
    "        sw_temp = True\n",
    "        if clim is not None:\n",
    "            sw_cats = True\n",
    "        else:\n",
    "            sw_cats = False\n",
    "    else:\n",
    "        sw_temp = False\n",
    "\n",
    "    #\n",
    "    # Initialize MHW output variable\n",
    "    #\n",
    "\n",
    "    mhwBlock = {}\n",
    "    mhwBlock['count'] = np.zeros(nBlocks)\n",
    "    mhwBlock['count'] = np.zeros(nBlocks)\n",
    "    mhwBlock['duration'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_max'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_max_max'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_mean'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_cumulative'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_var'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_max_relThresh'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_mean_relThresh'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_cumulative_relThresh'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_var_relThresh'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_max_abs'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_mean_abs'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_cumulative_abs'] = np.zeros(nBlocks)\n",
    "    mhwBlock['intensity_var_abs'] = np.zeros(nBlocks)\n",
    "    mhwBlock['rate_onset'] = np.zeros(nBlocks)\n",
    "    mhwBlock['rate_decline'] = np.zeros(nBlocks)\n",
    "    mhwBlock['total_days'] = np.zeros(nBlocks)\n",
    "    mhwBlock['total_icum'] = np.zeros(nBlocks)\n",
    "    if sw_temp:\n",
    "        mhwBlock['temp_mean'] = np.zeros(nBlocks)\n",
    "        mhwBlock['temp_max'] = np.zeros(nBlocks)\n",
    "        mhwBlock['temp_min'] = np.zeros(nBlocks)\n",
    "\n",
    "    # Calculate category days\n",
    "    if sw_cats:\n",
    "        mhwBlock['moderate_days'] = np.zeros(nBlocks)\n",
    "        mhwBlock['strong_days'] = np.zeros(nBlocks)\n",
    "        mhwBlock['severe_days'] = np.zeros(nBlocks)\n",
    "        mhwBlock['extreme_days'] = np.zeros(nBlocks)\n",
    "        cats = np.floor(1 + (temp - clim['thresh']) / (clim['thresh'] - clim['seas']))\n",
    "        mhwIndex = np.zeros(t.shape)\n",
    "        for ev in range(mhw['n_events']):\n",
    "            mhwIndex[mhw['index_start'][ev]:mhw['index_end'][ev]+1] = 1.\n",
    "\n",
    "\n",
    "    # Start, end, and centre years for all blocks\n",
    "    mhwBlock['years_start'] = years[range(0, len(years), blockLength)]\n",
    "    mhwBlock['years_end'] = mhwBlock['years_start'] + blockLength - 1\n",
    "    mhwBlock['years_centre'] = 0.5*(mhwBlock['years_start'] + mhwBlock['years_end'])\n",
    "\n",
    "    #\n",
    "    # Calculate block averages\n",
    "    #\n",
    "\n",
    "    for i in range(mhw['n_events']):\n",
    "        # Block index for year of each MHW (MHW year defined by start year)\n",
    "        iBlock = np.where((mhwBlock['years_start'] <= mhw['date_start'][i].year) * (mhwBlock['years_end'] >= mhw['date_start'][i].year))[0][0]\n",
    "        # Add MHW properties to block count\n",
    "        mhwBlock['count'][iBlock] += 1\n",
    "        mhwBlock['duration'][iBlock] += mhw['duration'][i]\n",
    "        mhwBlock['intensity_max'][iBlock] += mhw['intensity_max'][i]\n",
    "        mhwBlock['intensity_max_max'][iBlock] = np.max([mhwBlock['intensity_max_max'][iBlock], mhw['intensity_max'][i]])\n",
    "        mhwBlock['intensity_mean'][iBlock] += mhw['intensity_mean'][i]\n",
    "        mhwBlock['intensity_cumulative'][iBlock] += mhw['intensity_cumulative'][i]\n",
    "        mhwBlock['intensity_var'][iBlock] += mhw['intensity_var'][i]\n",
    "        mhwBlock['intensity_max_relThresh'][iBlock] += mhw['intensity_max_relThresh'][i]\n",
    "        mhwBlock['intensity_mean_relThresh'][iBlock] += mhw['intensity_mean_relThresh'][i]\n",
    "        mhwBlock['intensity_cumulative_relThresh'][iBlock] += mhw['intensity_cumulative_relThresh'][i]\n",
    "        mhwBlock['intensity_var_relThresh'][iBlock] += mhw['intensity_var_relThresh'][i]\n",
    "        mhwBlock['intensity_max_abs'][iBlock] += mhw['intensity_max_abs'][i]\n",
    "        mhwBlock['intensity_mean_abs'][iBlock] += mhw['intensity_mean_abs'][i]\n",
    "        mhwBlock['intensity_cumulative_abs'][iBlock] += mhw['intensity_cumulative_abs'][i]\n",
    "        mhwBlock['intensity_var_abs'][iBlock] += mhw['intensity_var_abs'][i]\n",
    "        mhwBlock['rate_onset'][iBlock] += mhw['rate_onset'][i]\n",
    "        mhwBlock['rate_decline'][iBlock] += mhw['rate_decline'][i]\n",
    "        if mhw['date_start'][i].year == mhw['date_end'][i].year: # MHW in single year\n",
    "            mhwBlock['total_days'][iBlock] += mhw['duration'][i]\n",
    "        else: # MHW spans multiple years\n",
    "            year_mhw = year[mhw['index_start'][i]:mhw['index_end'][i]+1]\n",
    "            for yr_mhw in np.unique(year_mhw):\n",
    "                iBlock = np.where((mhwBlock['years_start'] <= yr_mhw) * (mhwBlock['years_end'] >= yr_mhw))[0][0]\n",
    "                mhwBlock['total_days'][iBlock] += np.sum(year_mhw == yr_mhw)\n",
    "        # NOTE: icum for a MHW is assigned to its start year, even if it spans mult. years\n",
    "        mhwBlock['total_icum'][iBlock] += mhw['intensity_cumulative'][i]\n",
    "\n",
    "    # Calculation of category days\n",
    "    if sw_cats:\n",
    "        for i in range(int(nBlocks)):\n",
    "            mhwBlock['moderate_days'][i] = ((year >= mhwBlock['years_start'][i]) * (year <= mhwBlock['years_end'][i]) * mhwIndex * (cats == 1)).astype(int).sum()\n",
    "            mhwBlock['strong_days'][i] = ((year >= mhwBlock['years_start'][i]) * (year <= mhwBlock['years_end'][i]) * mhwIndex * (cats == 2)).astype(int).sum()\n",
    "            mhwBlock['severe_days'][i] = ((year >= mhwBlock['years_start'][i]) * (year <= mhwBlock['years_end'][i]) * mhwIndex * (cats == 3)).astype(int).sum()\n",
    "            mhwBlock['extreme_days'][i] = ((year >= mhwBlock['years_start'][i]) * (year <= mhwBlock['years_end'][i]) * mhwIndex * (cats >= 4)).astype(int).sum()\n",
    "\n",
    "    # Calculate averages\n",
    "    count = 1.*mhwBlock['count']\n",
    "    count[count==0] = np.nan\n",
    "    mhwBlock['duration'] = mhwBlock['duration'] / count\n",
    "    mhwBlock['intensity_max'] = mhwBlock['intensity_max'] / count\n",
    "    mhwBlock['intensity_mean'] = mhwBlock['intensity_mean'] / count\n",
    "    mhwBlock['intensity_cumulative'] = mhwBlock['intensity_cumulative'] / count\n",
    "    mhwBlock['intensity_var'] = mhwBlock['intensity_var'] / count\n",
    "    mhwBlock['intensity_max_relThresh'] = mhwBlock['intensity_max_relThresh'] / count\n",
    "    mhwBlock['intensity_mean_relThresh'] = mhwBlock['intensity_mean_relThresh'] / count\n",
    "    mhwBlock['intensity_cumulative_relThresh'] = mhwBlock['intensity_cumulative_relThresh'] / count\n",
    "    mhwBlock['intensity_var_relThresh'] = mhwBlock['intensity_var_relThresh'] / count\n",
    "    mhwBlock['intensity_max_abs'] = mhwBlock['intensity_max_abs'] / count\n",
    "    mhwBlock['intensity_mean_abs'] = mhwBlock['intensity_mean_abs'] / count\n",
    "    mhwBlock['intensity_cumulative_abs'] = mhwBlock['intensity_cumulative_abs'] / count\n",
    "    mhwBlock['intensity_var_abs'] = mhwBlock['intensity_var_abs'] / count\n",
    "    mhwBlock['rate_onset'] = mhwBlock['rate_onset'] / count\n",
    "    mhwBlock['rate_decline'] = mhwBlock['rate_decline'] / count\n",
    "    # Replace empty years in intensity_max_max\n",
    "    mhwBlock['intensity_max_max'][np.isnan(mhwBlock['intensity_max'])] = np.nan\n",
    "\n",
    "    # Temperature series\n",
    "    if sw_temp:\n",
    "        for i in range(int(nBlocks)):\n",
    "            tt = (year >= mhwBlock['years_start'][i]) * (year <= mhwBlock['years_end'][i])\n",
    "            mhwBlock['temp_mean'][i] = np.nanmean(temp[tt])\n",
    "            mhwBlock['temp_max'][i] = np.nanmax(temp[tt])\n",
    "            mhwBlock['temp_min'][i] = np.nanmin(temp[tt])\n",
    "\n",
    "    #\n",
    "    # Remove years with missing values\n",
    "    #\n",
    "\n",
    "    if removeMissing:\n",
    "        missingYears = np.unique(year[np.where(clim['missing'])[0]])\n",
    "        for y in range(len(missingYears)):\n",
    "            iMissing = np.where((mhwBlock['years_start'] <= missingYears[y]) * (mhwBlock['years_end'] >= missingYears[y]))[0][0]\n",
    "            mhwBlock['count'][iMissing] = np.nan\n",
    "            mhwBlock['duration'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_max'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_max_max'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_mean'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_cumulative'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_var'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_max_relThresh'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_mean_relThresh'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_cumulative_relThresh'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_var_relThresh'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_max_abs'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_mean_abs'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_cumulative_abs'][iMissing] = np.nan\n",
    "            mhwBlock['intensity_var_abs'][iMissing] = np.nan\n",
    "            mhwBlock['rate_onset'][iMissing] = np.nan\n",
    "            mhwBlock['rate_decline'][iMissing] = np.nan\n",
    "            mhwBlock['total_days'][iMissing] = np.nan\n",
    "            if sw_cats:\n",
    "                mhwBlock['moderate_days'][iMissing] = np.nan\n",
    "                mhwBlock['strong_days'][iMissing] = np.nan\n",
    "                mhwBlock['severe_days'][iMissing] = np.nan\n",
    "                mhwBlock['extreme_days'][iMissing] = np.nan\n",
    "            mhwBlock['total_icum'][iMissing] = np.nan\n",
    "\n",
    "    return mhwBlock\n",
    "\n",
    "\n",
    "def meanTrend(mhwBlock, alpha=0.05):\n",
    "    '''\n",
    "    Calculates the mean and trend of marine heatwave (MHW) properties. Takes as input a\n",
    "    collection of block-averaged MHW properties (using the marineHeatWaves.blockAverage\n",
    "    function). Handles missing values (which should be specified by NaNs).\n",
    "    Inputs:\n",
    "      mhwBlock      Time series of block-averaged MHW statistics calculated using the\n",
    "                    marineHeatWaves.blockAverage function\n",
    "      alpha         Significance level for estimate of confidence limits on trend, e.g.,\n",
    "                    alpha = 0.05 for 5% significance (or 95% confidence) (DEFAULT = 0.05)\n",
    "    Outputs:\n",
    "      mean          Mean of all MHW properties over all block-averaged values\n",
    "      trend         Linear trend of all MHW properties over all block-averaged values\n",
    "      dtrend        One-sided width of (1-alpha)% confidence intevfal on linear trend,\n",
    "                    i.e., trend lies within (trend-dtrend, trend+dtrend) with specified\n",
    "                    level  of confidence.\n",
    "                    Both mean and trend have the following keys, the units the trend\n",
    "                    are the units of the property of interest per year:\n",
    "        'duration'             Duration of MHW [days]\n",
    "        'intensity_max'        Maximum (peak) intensity [deg. C]\n",
    "        'intensity_mean'       Mean intensity [deg. C]\n",
    "        'intensity_var'        Intensity variability [deg. C]\n",
    "        'intensity_cumulative' Cumulative intensity [deg. C x days]\n",
    "        'rate_onset'           Onset rate of MHW [deg. C / days]\n",
    "        'rate_decline'         Decline rate of MHW [deg. C / days]\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "    Notes:\n",
    "      This calculation performs a multiple linear regression of the form\n",
    "        y ~ beta * X + eps\n",
    "      where y is the MHW property of interest and X is a matrix of predictors. The first\n",
    "      column of X is all ones to estimate the mean, the second column is the time vector\n",
    "      which is taken as mhwBlock['years_centre'] and offset to be equal to zero at its\n",
    "      mid-point.\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb-Mar 2015\n",
    "    '''\n",
    "\n",
    "    # Initialize mean and trend dictionaries\n",
    "    mean = {}\n",
    "    trend = {}\n",
    "    dtrend = {}\n",
    "\n",
    "    # Construct matrix of predictors, first column is all ones to estimate the mean,\n",
    "    # second column is the time vector, equal to zero at mid-point.\n",
    "    t = mhwBlock['years_centre']\n",
    "    X = np.array([np.ones(t.shape), t-t.mean()]).T\n",
    "\n",
    "    # Loop over all keys in mhwBlock\n",
    "    for key in mhwBlock.keys():\n",
    "        # Skip time-vector keys of mhwBlock\n",
    "        if (key == 'years_centre') + (key == 'years_end') + (key == 'years_start'):\n",
    "            continue\n",
    "\n",
    "        # Predictand (MHW property of interest)\n",
    "        y = mhwBlock[key]\n",
    "        valid = ~np.isnan(y) # non-NaN indices\n",
    "\n",
    "        # Perform linear regression over valid indices\n",
    "        if np.isinf(nonans(y).sum()): # If contains Inf values\n",
    "            beta = [np.nan, np.nan]\n",
    "        elif np.sum(~np.isnan(y)) > 0: # If at least one non-NaN value\n",
    "            beta = linalg.lstsq(X[valid,:], y[valid])[0]\n",
    "        else:\n",
    "            beta = [np.nan, np.nan]\n",
    "\n",
    "        # Insert regression coefficients into mean and trend dictionaries\n",
    "        mean[key] = beta[0]\n",
    "        trend[key] = beta[1]\n",
    "\n",
    "        # Confidence limits on trend\n",
    "        yhat = np.sum(beta*X, axis=1)\n",
    "        t_stat = stats.t.isf(alpha/2, len(t[valid])-2)\n",
    "        s = np.sqrt(np.sum((y[valid] - yhat[valid])**2) / (len(t[valid])-2))\n",
    "        Sxx = np.sum(X[valid,1]**2) - (np.sum(X[valid,1])**2)/len(t[valid]) # np.var(X, axis=1)[1]\n",
    "        dbeta1 = t_stat * s / np.sqrt(Sxx)\n",
    "        dtrend[key] = dbeta1\n",
    "\n",
    "    # Return mean, trend\n",
    "    return mean, trend, dtrend\n",
    "\n",
    "\n",
    "def rank(t, mhw):\n",
    "    '''\n",
    "    Calculate the rank and return periods of marine heatwaves (MHWs) according to\n",
    "    each metric. Takes as input a collection of detected MHWs (using the\n",
    "    marineHeatWaves.detect function) and a time vector for the source SST series.\n",
    "    Inputs:\n",
    "      t       Time vector, in datetime format (e.g., date(1982,1,1).toordinal())\n",
    "      mhw     Marine heat waves (MHWs) detected using marineHeatWaves.detect\n",
    "    Outputs:\n",
    "      rank          The rank of each MHW according to each MHW property. A rank of 1 is the\n",
    "                    largest, 2 is the 2nd largest, etc. Each key (listed below) is a list\n",
    "                    of length N where N is the number of MHWs.\n",
    "      returnPeriod  The return period (in years) of each MHW according to each MHW property.\n",
    "                    The return period signifies, statistically, the recurrence interval for\n",
    "                    an event at least as large/long as the event in quetion. Each key (listed\n",
    "                    below) is a list of length N where N is the number of MHWs.\n",
    " \n",
    "        'duration'             Average MHW duration in each block [days]\n",
    "        'intensity_max'        Average MHW \"maximum (peak) intensity\" in each block [deg. C]\n",
    "        'intensity_mean'       Average MHW \"mean intensity\" in each block [deg. C]\n",
    "        'intensity_var'        Average MHW \"intensity variability\" in each block [deg. C]\n",
    "        'intensity_cumulative' Average MHW \"cumulative intensity\" in each block [deg. C x days]\n",
    "        'rate_onset'           Average MHW onset rate in each block [deg. C / days]\n",
    "        'rate_decline'         Average MHW decline rate in each block [deg. C / days]\n",
    "        'total_days'           Total number of MHW days in each block [days]\n",
    "        'total_icum'           Total cumulative intensity over all MHWs in each block [deg. C x days]\n",
    "        'intensity_max_relThresh', 'intensity_mean_relThresh', 'intensity_var_relThresh', \n",
    "        and 'intensity_cumulative_relThresh' are as above except relative to the\n",
    "        threshold (e.g., 90th percentile) rather than the seasonal climatology\n",
    "        'intensity_max_abs', 'intensity_mean_abs', 'intensity_var_abs', and\n",
    "        'intensity_cumulative_abs' are as above except as absolute magnitudes\n",
    "        rather than relative to the seasonal climatology or threshold\n",
    "    Notes:\n",
    "      This function assumes that the MHWs were calculated over a suitably long record that return\n",
    "      periods make sense. If the record length is a few years or less than this becomes meaningless.\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Sep 2015\n",
    "    '''\n",
    "\n",
    "    # Initialize rank and return period dictionaries\n",
    "    rank = {}\n",
    "    returnPeriod = {}\n",
    "\n",
    "    # Number of years on record\n",
    "    nYears = len(t)/365.25\n",
    "\n",
    "    # Loop over all keys in mhw\n",
    "    for key in mhw.keys():\n",
    "        # Skip irrelevant keys of mhw, only calculate rank/returns for MHW properties\n",
    "        if (key == 'date_end') + (key == 'date_peak') + (key == 'date_start') + (key == 'date_end') + (key == 'date_peak') + (key == 'date_start') + (key == 'index_end') + (key == 'index_peak') + (key == 'index_start') + (key == 'n_events'):\n",
    "            continue\n",
    "\n",
    "        # Calculate ranks\n",
    "        rank[key] = mhw['n_events'] - np.array(mhw[key]).argsort().argsort()  \n",
    "        # Calculate return period as (# years on record + 1) / (# of occurrences of event)\n",
    "        # Return period is for events of at least the event magnitude/duration\n",
    "        returnPeriod[key] = (nYears + 1) / rank[key]\n",
    "\n",
    "    # Return rank, return\n",
    "    return rank, returnPeriod\n",
    "\n",
    "\n",
    "def runavg(ts, w):\n",
    "    '''\n",
    "    Performs a running average of an input time series using uniform window\n",
    "    of width w. This function assumes that the input time series is periodic.\n",
    "    Inputs:\n",
    "      ts            Time series [1D numpy array]\n",
    "      w             Integer length (must be odd) of running average window\n",
    "    Outputs:\n",
    "      ts_smooth     Smoothed time series\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Feb-Mar 2015\n",
    "    '''\n",
    "    # Original length of ts\n",
    "    N = len(ts)\n",
    "    # make ts three-fold periodic\n",
    "    ts = np.append(ts, np.append(ts, ts))\n",
    "    # smooth by convolution with a window of equal weights\n",
    "    ts_smooth = np.convolve(ts, np.ones(w)/w, mode='same')\n",
    "    # Only output central section, of length equal to the original length of ts\n",
    "    ts = ts_smooth[N:2*N]\n",
    "\n",
    "    return ts\n",
    "\n",
    "\n",
    "def pad(data, maxPadLength=False):\n",
    "    '''\n",
    "    Linearly interpolate over missing data (NaNs) in a time series.\n",
    "    Inputs:\n",
    "      data\t     Time series [1D numpy array]\n",
    "      maxPadLength   Specifies the maximum length over which to interpolate,\n",
    "                     i.e., any consecutive blocks of NaNs with length greater\n",
    "                     than maxPadLength will be left as NaN. Set as an integer.\n",
    "                     maxPadLength=False (default) interpolates over all NaNs.\n",
    "    Written by Eric Oliver, Institue for Marine and Antarctic Studies, University of Tasmania, Jun 2015\n",
    "    '''\n",
    "    data_padded = data.copy()\n",
    "    bad_indexes = np.isnan(data)\n",
    "    good_indexes = np.logical_not(bad_indexes)\n",
    "    good_data = data[good_indexes]\n",
    "    interpolated = np.interp(bad_indexes.nonzero()[0], good_indexes.nonzero()[0], good_data)\n",
    "    data_padded[bad_indexes] = interpolated\n",
    "    if maxPadLength:\n",
    "        blocks, n_blocks = ndimage.label(np.isnan(data))\n",
    "        for bl in range(1, n_blocks+1):\n",
    "            if (blocks==bl).sum() > maxPadLength:\n",
    "                data_padded[blocks==bl] = np.nan\n",
    "\n",
    "    return data_padded\n",
    "\n",
    "\n",
    "def nonans(array):\n",
    "    '''\n",
    "    Return input array [1D numpy array] with\n",
    "    all nan values removed\n",
    "    '''\n",
    "    return array[~np.isnan(array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "16ba546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14610, 82, 82)\n",
      "[-30.125 -29.875 -29.625 -29.375 -29.125 -28.875 -28.625 -28.375 -28.125\n",
      " -27.875 -27.625 -27.375 -27.125 -26.875 -26.625 -26.375 -26.125 -25.875\n",
      " -25.625 -25.375 -25.125 -24.875 -24.625 -24.375 -24.125 -23.875 -23.625\n",
      " -23.375 -23.125 -22.875 -22.625 -22.375 -22.125 -21.875 -21.625 -21.375\n",
      " -21.125 -20.875 -20.625 -20.375 -20.125 -19.875 -19.625 -19.375 -19.125\n",
      " -18.875 -18.625 -18.375 -18.125 -17.875 -17.625 -17.375 -17.125 -16.875\n",
      " -16.625 -16.375 -16.125 -15.875 -15.625 -15.375 -15.125 -14.875 -14.625\n",
      " -14.375 -14.125 -13.875 -13.625 -13.375 -13.125 -12.875 -12.625 -12.375\n",
      " -12.125 -11.875 -11.625 -11.375 -11.125 -10.875 -10.625 -10.375 -10.125\n",
      "  -9.875]\n",
      "[329.875 330.125 330.375 330.625 330.875 331.125 331.375 331.625 331.875\n",
      " 332.125 332.375 332.625 332.875 333.125 333.375 333.625 333.875 334.125\n",
      " 334.375 334.625 334.875 335.125 335.375 335.625 335.875 336.125 336.375\n",
      " 336.625 336.875 337.125 337.375 337.625 337.875 338.125 338.375 338.625\n",
      " 338.875 339.125 339.375 339.625 339.875 340.125 340.375 340.625 340.875\n",
      " 341.125 341.375 341.625 341.875 342.125 342.375 342.625 342.875 343.125\n",
      " 343.375 343.625 343.875 344.125 344.375 344.625 344.875 345.125 345.375\n",
      " 345.625 345.875 346.125 346.375 346.625 346.875 347.125 347.375 347.625\n",
      " 347.875 348.125 348.375 348.625 348.875 349.125 349.375 349.625 349.875\n",
      " 350.125]\n"
     ]
    }
   ],
   "source": [
    "t = np.arange(date(1982,1,1).toordinal(),date(2021,12,31).toordinal()+1)\n",
    "dates = [date.fromordinal(tt.astype(int)) for tt in t]\n",
    "# Generate synthetic temperature time series\n",
    "\n",
    "data = np.load(r'D:\\heat_wave\\atlantic\\SST_82_21_expand_atlantic_area.npz')\n",
    "sst = data['sst'][:]\n",
    "print(sst.shape) #(9861, 30, 41, 201)\n",
    "lat = data['lat'][:]\n",
    "print(lat)\n",
    "lon = data['lon'][:]\n",
    "print(lon)\n",
    "\n",
    "# # data = data[:,0,:,:]\n",
    "# print(np.min(data))\n",
    "\n",
    "# sst = np.mean(data, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "43199376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_start': [724232,\n",
       "  724259,\n",
       "  725649,\n",
       "  725696,\n",
       "  725777,\n",
       "  725822,\n",
       "  726384,\n",
       "  727811,\n",
       "  727824,\n",
       "  727886,\n",
       "  728407,\n",
       "  729329,\n",
       "  729445,\n",
       "  729580,\n",
       "  731042,\n",
       "  731098,\n",
       "  731178,\n",
       "  731226,\n",
       "  731248,\n",
       "  731312,\n",
       "  731363,\n",
       "  731433,\n",
       "  731501,\n",
       "  731560,\n",
       "  731790,\n",
       "  731817,\n",
       "  733154,\n",
       "  733670,\n",
       "  733898,\n",
       "  735085,\n",
       "  735109,\n",
       "  735268,\n",
       "  735296,\n",
       "  735610,\n",
       "  735681,\n",
       "  735946,\n",
       "  736023,\n",
       "  736126,\n",
       "  736244,\n",
       "  736307,\n",
       "  736336,\n",
       "  737072,\n",
       "  737105,\n",
       "  737251,\n",
       "  737264,\n",
       "  737272,\n",
       "  737314,\n",
       "  737380,\n",
       "  737433,\n",
       "  737499,\n",
       "  737578,\n",
       "  737640,\n",
       "  737930],\n",
       " 'time_end': [724242,\n",
       "  724263,\n",
       "  725687,\n",
       "  725721,\n",
       "  725784,\n",
       "  725834,\n",
       "  726389,\n",
       "  727818,\n",
       "  727850,\n",
       "  727892,\n",
       "  728416,\n",
       "  729334,\n",
       "  729452,\n",
       "  729595,\n",
       "  731047,\n",
       "  731106,\n",
       "  731193,\n",
       "  731244,\n",
       "  731290,\n",
       "  731345,\n",
       "  731390,\n",
       "  731459,\n",
       "  731525,\n",
       "  731564,\n",
       "  731797,\n",
       "  731826,\n",
       "  733162,\n",
       "  733880,\n",
       "  733951,\n",
       "  735093,\n",
       "  735114,\n",
       "  735285,\n",
       "  735305,\n",
       "  735646,\n",
       "  735688,\n",
       "  735955,\n",
       "  736028,\n",
       "  736240,\n",
       "  736249,\n",
       "  736313,\n",
       "  736355,\n",
       "  737094,\n",
       "  737238,\n",
       "  737260,\n",
       "  737268,\n",
       "  737279,\n",
       "  737318,\n",
       "  737386,\n",
       "  737449,\n",
       "  737565,\n",
       "  737593,\n",
       "  737647,\n",
       "  737944],\n",
       " 'time_peak': [724239,\n",
       "  724261,\n",
       "  725681,\n",
       "  725715,\n",
       "  725782,\n",
       "  725826,\n",
       "  726388,\n",
       "  727813,\n",
       "  727841,\n",
       "  727890,\n",
       "  728413,\n",
       "  729331,\n",
       "  729447,\n",
       "  729587,\n",
       "  731043,\n",
       "  731099,\n",
       "  731190,\n",
       "  731235,\n",
       "  731269,\n",
       "  731334,\n",
       "  731381,\n",
       "  731445,\n",
       "  731511,\n",
       "  731561,\n",
       "  731793,\n",
       "  731821,\n",
       "  733157,\n",
       "  733784,\n",
       "  733920,\n",
       "  735087,\n",
       "  735110,\n",
       "  735281,\n",
       "  735302,\n",
       "  735633,\n",
       "  735686,\n",
       "  735953,\n",
       "  736027,\n",
       "  736195,\n",
       "  736247,\n",
       "  736307,\n",
       "  736352,\n",
       "  737089,\n",
       "  737115,\n",
       "  737255,\n",
       "  737266,\n",
       "  737275,\n",
       "  737317,\n",
       "  737386,\n",
       "  737436,\n",
       "  737563,\n",
       "  737579,\n",
       "  737641,\n",
       "  737939],\n",
       " 'date_start': [datetime.date(1983, 11, 18),\n",
       "  datetime.date(1983, 12, 15),\n",
       "  datetime.date(1987, 10, 5),\n",
       "  datetime.date(1987, 11, 21),\n",
       "  datetime.date(1988, 2, 10),\n",
       "  datetime.date(1988, 3, 26),\n",
       "  datetime.date(1989, 10, 9),\n",
       "  datetime.date(1993, 9, 5),\n",
       "  datetime.date(1993, 9, 18),\n",
       "  datetime.date(1993, 11, 19),\n",
       "  datetime.date(1995, 4, 24),\n",
       "  datetime.date(1997, 11, 1),\n",
       "  datetime.date(1998, 2, 25),\n",
       "  datetime.date(1998, 7, 10),\n",
       "  datetime.date(2002, 7, 11),\n",
       "  datetime.date(2002, 9, 5),\n",
       "  datetime.date(2002, 11, 24),\n",
       "  datetime.date(2003, 1, 11),\n",
       "  datetime.date(2003, 2, 2),\n",
       "  datetime.date(2003, 4, 7),\n",
       "  datetime.date(2003, 5, 28),\n",
       "  datetime.date(2003, 8, 6),\n",
       "  datetime.date(2003, 10, 13),\n",
       "  datetime.date(2003, 12, 11),\n",
       "  datetime.date(2004, 7, 28),\n",
       "  datetime.date(2004, 8, 24),\n",
       "  datetime.date(2008, 4, 22),\n",
       "  datetime.date(2009, 9, 20),\n",
       "  datetime.date(2010, 5, 6),\n",
       "  datetime.date(2013, 8, 5),\n",
       "  datetime.date(2013, 8, 29),\n",
       "  datetime.date(2014, 2, 4),\n",
       "  datetime.date(2014, 3, 4),\n",
       "  datetime.date(2015, 1, 12),\n",
       "  datetime.date(2015, 3, 24),\n",
       "  datetime.date(2015, 12, 14),\n",
       "  datetime.date(2016, 2, 29),\n",
       "  datetime.date(2016, 6, 11),\n",
       "  datetime.date(2016, 10, 7),\n",
       "  datetime.date(2016, 12, 9),\n",
       "  datetime.date(2017, 1, 7),\n",
       "  datetime.date(2019, 1, 13),\n",
       "  datetime.date(2019, 2, 15),\n",
       "  datetime.date(2019, 7, 11),\n",
       "  datetime.date(2019, 7, 24),\n",
       "  datetime.date(2019, 8, 1),\n",
       "  datetime.date(2019, 9, 12),\n",
       "  datetime.date(2019, 11, 17),\n",
       "  datetime.date(2020, 1, 9),\n",
       "  datetime.date(2020, 3, 15),\n",
       "  datetime.date(2020, 6, 2),\n",
       "  datetime.date(2020, 8, 3),\n",
       "  datetime.date(2021, 5, 20)],\n",
       " 'date_end': [datetime.date(1983, 11, 28),\n",
       "  datetime.date(1983, 12, 19),\n",
       "  datetime.date(1987, 11, 12),\n",
       "  datetime.date(1987, 12, 16),\n",
       "  datetime.date(1988, 2, 17),\n",
       "  datetime.date(1988, 4, 7),\n",
       "  datetime.date(1989, 10, 14),\n",
       "  datetime.date(1993, 9, 12),\n",
       "  datetime.date(1993, 10, 14),\n",
       "  datetime.date(1993, 11, 25),\n",
       "  datetime.date(1995, 5, 3),\n",
       "  datetime.date(1997, 11, 6),\n",
       "  datetime.date(1998, 3, 4),\n",
       "  datetime.date(1998, 7, 25),\n",
       "  datetime.date(2002, 7, 16),\n",
       "  datetime.date(2002, 9, 13),\n",
       "  datetime.date(2002, 12, 9),\n",
       "  datetime.date(2003, 1, 29),\n",
       "  datetime.date(2003, 3, 16),\n",
       "  datetime.date(2003, 5, 10),\n",
       "  datetime.date(2003, 6, 24),\n",
       "  datetime.date(2003, 9, 1),\n",
       "  datetime.date(2003, 11, 6),\n",
       "  datetime.date(2003, 12, 15),\n",
       "  datetime.date(2004, 8, 4),\n",
       "  datetime.date(2004, 9, 2),\n",
       "  datetime.date(2008, 4, 30),\n",
       "  datetime.date(2010, 4, 18),\n",
       "  datetime.date(2010, 6, 28),\n",
       "  datetime.date(2013, 8, 13),\n",
       "  datetime.date(2013, 9, 3),\n",
       "  datetime.date(2014, 2, 21),\n",
       "  datetime.date(2014, 3, 13),\n",
       "  datetime.date(2015, 2, 17),\n",
       "  datetime.date(2015, 3, 31),\n",
       "  datetime.date(2015, 12, 23),\n",
       "  datetime.date(2016, 3, 5),\n",
       "  datetime.date(2016, 10, 3),\n",
       "  datetime.date(2016, 10, 12),\n",
       "  datetime.date(2016, 12, 15),\n",
       "  datetime.date(2017, 1, 26),\n",
       "  datetime.date(2019, 2, 4),\n",
       "  datetime.date(2019, 6, 28),\n",
       "  datetime.date(2019, 7, 20),\n",
       "  datetime.date(2019, 7, 28),\n",
       "  datetime.date(2019, 8, 8),\n",
       "  datetime.date(2019, 9, 16),\n",
       "  datetime.date(2019, 11, 23),\n",
       "  datetime.date(2020, 1, 25),\n",
       "  datetime.date(2020, 5, 20),\n",
       "  datetime.date(2020, 6, 17),\n",
       "  datetime.date(2020, 8, 10),\n",
       "  datetime.date(2021, 6, 3)],\n",
       " 'date_peak': [datetime.date(1983, 11, 25),\n",
       "  datetime.date(1983, 12, 17),\n",
       "  datetime.date(1987, 11, 6),\n",
       "  datetime.date(1987, 12, 10),\n",
       "  datetime.date(1988, 2, 15),\n",
       "  datetime.date(1988, 3, 30),\n",
       "  datetime.date(1989, 10, 13),\n",
       "  datetime.date(1993, 9, 7),\n",
       "  datetime.date(1993, 10, 5),\n",
       "  datetime.date(1993, 11, 23),\n",
       "  datetime.date(1995, 4, 30),\n",
       "  datetime.date(1997, 11, 3),\n",
       "  datetime.date(1998, 2, 27),\n",
       "  datetime.date(1998, 7, 17),\n",
       "  datetime.date(2002, 7, 12),\n",
       "  datetime.date(2002, 9, 6),\n",
       "  datetime.date(2002, 12, 6),\n",
       "  datetime.date(2003, 1, 20),\n",
       "  datetime.date(2003, 2, 23),\n",
       "  datetime.date(2003, 4, 29),\n",
       "  datetime.date(2003, 6, 15),\n",
       "  datetime.date(2003, 8, 18),\n",
       "  datetime.date(2003, 10, 23),\n",
       "  datetime.date(2003, 12, 12),\n",
       "  datetime.date(2004, 7, 31),\n",
       "  datetime.date(2004, 8, 28),\n",
       "  datetime.date(2008, 4, 25),\n",
       "  datetime.date(2010, 1, 12),\n",
       "  datetime.date(2010, 5, 28),\n",
       "  datetime.date(2013, 8, 7),\n",
       "  datetime.date(2013, 8, 30),\n",
       "  datetime.date(2014, 2, 17),\n",
       "  datetime.date(2014, 3, 10),\n",
       "  datetime.date(2015, 2, 4),\n",
       "  datetime.date(2015, 3, 29),\n",
       "  datetime.date(2015, 12, 21),\n",
       "  datetime.date(2016, 3, 4),\n",
       "  datetime.date(2016, 8, 19),\n",
       "  datetime.date(2016, 10, 10),\n",
       "  datetime.date(2016, 12, 9),\n",
       "  datetime.date(2017, 1, 23),\n",
       "  datetime.date(2019, 1, 30),\n",
       "  datetime.date(2019, 2, 25),\n",
       "  datetime.date(2019, 7, 15),\n",
       "  datetime.date(2019, 7, 26),\n",
       "  datetime.date(2019, 8, 4),\n",
       "  datetime.date(2019, 9, 15),\n",
       "  datetime.date(2019, 11, 23),\n",
       "  datetime.date(2020, 1, 12),\n",
       "  datetime.date(2020, 5, 18),\n",
       "  datetime.date(2020, 6, 3),\n",
       "  datetime.date(2020, 8, 4),\n",
       "  datetime.date(2021, 5, 29)],\n",
       " 'index_start': [686,\n",
       "  713,\n",
       "  2103,\n",
       "  2150,\n",
       "  2231,\n",
       "  2276,\n",
       "  2838,\n",
       "  4265,\n",
       "  4278,\n",
       "  4340,\n",
       "  4861,\n",
       "  5783,\n",
       "  5899,\n",
       "  6034,\n",
       "  7496,\n",
       "  7552,\n",
       "  7632,\n",
       "  7680,\n",
       "  7702,\n",
       "  7766,\n",
       "  7817,\n",
       "  7887,\n",
       "  7955,\n",
       "  8014,\n",
       "  8244,\n",
       "  8271,\n",
       "  9608,\n",
       "  10124,\n",
       "  10352,\n",
       "  11539,\n",
       "  11563,\n",
       "  11722,\n",
       "  11750,\n",
       "  12064,\n",
       "  12135,\n",
       "  12400,\n",
       "  12477,\n",
       "  12580,\n",
       "  12698,\n",
       "  12761,\n",
       "  12790,\n",
       "  13526,\n",
       "  13559,\n",
       "  13705,\n",
       "  13718,\n",
       "  13726,\n",
       "  13768,\n",
       "  13834,\n",
       "  13887,\n",
       "  13953,\n",
       "  14032,\n",
       "  14094,\n",
       "  14384],\n",
       " 'index_end': [696,\n",
       "  717,\n",
       "  2141,\n",
       "  2175,\n",
       "  2238,\n",
       "  2288,\n",
       "  2843,\n",
       "  4272,\n",
       "  4304,\n",
       "  4346,\n",
       "  4870,\n",
       "  5788,\n",
       "  5906,\n",
       "  6049,\n",
       "  7501,\n",
       "  7560,\n",
       "  7647,\n",
       "  7698,\n",
       "  7744,\n",
       "  7799,\n",
       "  7844,\n",
       "  7913,\n",
       "  7979,\n",
       "  8018,\n",
       "  8251,\n",
       "  8280,\n",
       "  9616,\n",
       "  10334,\n",
       "  10405,\n",
       "  11547,\n",
       "  11568,\n",
       "  11739,\n",
       "  11759,\n",
       "  12100,\n",
       "  12142,\n",
       "  12409,\n",
       "  12482,\n",
       "  12694,\n",
       "  12703,\n",
       "  12767,\n",
       "  12809,\n",
       "  13548,\n",
       "  13692,\n",
       "  13714,\n",
       "  13722,\n",
       "  13733,\n",
       "  13772,\n",
       "  13840,\n",
       "  13903,\n",
       "  14019,\n",
       "  14047,\n",
       "  14101,\n",
       "  14398],\n",
       " 'index_peak': [693,\n",
       "  715,\n",
       "  2135,\n",
       "  2169,\n",
       "  2236,\n",
       "  2280,\n",
       "  2842,\n",
       "  4267,\n",
       "  4295,\n",
       "  4344,\n",
       "  4867,\n",
       "  5785,\n",
       "  5901,\n",
       "  6041,\n",
       "  7497,\n",
       "  7553,\n",
       "  7644,\n",
       "  7689,\n",
       "  7723,\n",
       "  7788,\n",
       "  7835,\n",
       "  7899,\n",
       "  7965,\n",
       "  8015,\n",
       "  8247,\n",
       "  8275,\n",
       "  9611,\n",
       "  10238,\n",
       "  10374,\n",
       "  11541,\n",
       "  11564,\n",
       "  11735,\n",
       "  11756,\n",
       "  12087,\n",
       "  12140,\n",
       "  12407,\n",
       "  12481,\n",
       "  12649,\n",
       "  12701,\n",
       "  12761,\n",
       "  12806,\n",
       "  13543,\n",
       "  13569,\n",
       "  13709,\n",
       "  13720,\n",
       "  13729,\n",
       "  13771,\n",
       "  13840,\n",
       "  13890,\n",
       "  14017,\n",
       "  14033,\n",
       "  14095,\n",
       "  14393],\n",
       " 'duration': [11,\n",
       "  5,\n",
       "  39,\n",
       "  26,\n",
       "  8,\n",
       "  13,\n",
       "  6,\n",
       "  8,\n",
       "  27,\n",
       "  7,\n",
       "  10,\n",
       "  6,\n",
       "  8,\n",
       "  16,\n",
       "  6,\n",
       "  9,\n",
       "  16,\n",
       "  19,\n",
       "  43,\n",
       "  34,\n",
       "  28,\n",
       "  27,\n",
       "  25,\n",
       "  5,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  211,\n",
       "  54,\n",
       "  9,\n",
       "  6,\n",
       "  18,\n",
       "  10,\n",
       "  37,\n",
       "  8,\n",
       "  10,\n",
       "  6,\n",
       "  115,\n",
       "  6,\n",
       "  7,\n",
       "  20,\n",
       "  23,\n",
       "  134,\n",
       "  10,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  7,\n",
       "  17,\n",
       "  67,\n",
       "  16,\n",
       "  8,\n",
       "  15],\n",
       " 'duration_moderate': [11,\n",
       "  5,\n",
       "  39,\n",
       "  24,\n",
       "  8,\n",
       "  13,\n",
       "  6,\n",
       "  8,\n",
       "  27,\n",
       "  7,\n",
       "  10,\n",
       "  6,\n",
       "  8,\n",
       "  16,\n",
       "  6,\n",
       "  9,\n",
       "  16,\n",
       "  19,\n",
       "  42,\n",
       "  32,\n",
       "  26,\n",
       "  25,\n",
       "  21,\n",
       "  5,\n",
       "  8,\n",
       "  10,\n",
       "  9,\n",
       "  113,\n",
       "  54,\n",
       "  9,\n",
       "  6,\n",
       "  18,\n",
       "  10,\n",
       "  35,\n",
       "  8,\n",
       "  10,\n",
       "  6,\n",
       "  115,\n",
       "  6,\n",
       "  7,\n",
       "  20,\n",
       "  23,\n",
       "  99,\n",
       "  10,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  7,\n",
       "  17,\n",
       "  67,\n",
       "  15,\n",
       "  8,\n",
       "  15],\n",
       " 'duration_strong': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  98,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  31,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'duration_severe': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'duration_extreme': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'intensity_max': [0.7697995093560976,\n",
       "  0.6148944977791118,\n",
       "  0.8207602347097165,\n",
       "  0.8642372623566565,\n",
       "  0.945024521120132,\n",
       "  0.707503164968184,\n",
       "  0.4894813414542938,\n",
       "  0.5863446881694152,\n",
       "  0.7291539099908704,\n",
       "  0.7057253929876524,\n",
       "  0.7458897252236625,\n",
       "  0.6250921064807571,\n",
       "  0.6942508143763426,\n",
       "  0.7748043921685976,\n",
       "  0.5573046284337124,\n",
       "  0.5456815535022344,\n",
       "  0.684823436121782,\n",
       "  1.1452461365730535,\n",
       "  1.0943623512021965,\n",
       "  0.8672770223309882,\n",
       "  0.6523393815563594,\n",
       "  0.9007235496274895,\n",
       "  0.966707660305886,\n",
       "  0.640365416003803,\n",
       "  0.5628307711693559,\n",
       "  0.6145671721427632,\n",
       "  0.7425863819737586,\n",
       "  1.4565170041976465,\n",
       "  0.9197503982051707,\n",
       "  0.5436041432042273,\n",
       "  0.49934491803569614,\n",
       "  1.0503717545540106,\n",
       "  0.7444284192977477,\n",
       "  1.188613830074189,\n",
       "  0.6141751197076601,\n",
       "  0.9529598605248246,\n",
       "  0.7072009732646407,\n",
       "  0.771392206991873,\n",
       "  0.4906042160526418,\n",
       "  0.5560042473577589,\n",
       "  1.068419794882498,\n",
       "  0.9039592742919922,\n",
       "  1.2992451883131473,\n",
       "  0.7125336431687828,\n",
       "  0.5750937923308364,\n",
       "  0.6048599366218816,\n",
       "  0.4361358765632879,\n",
       "  0.5653941246771055,\n",
       "  1.091858648484756,\n",
       "  0.726611660372825,\n",
       "  0.6963238254670117,\n",
       "  0.46307526865313164,\n",
       "  0.6730377443375097],\n",
       " 'intensity_mean': [0.6558789395866517,\n",
       "  0.5594400590465931,\n",
       "  0.6063713676383254,\n",
       "  0.6458416600381158,\n",
       "  0.8452536905965506,\n",
       "  0.6116753713072988,\n",
       "  0.4381762268722718,\n",
       "  0.4800693065889412,\n",
       "  0.5816520818530319,\n",
       "  0.5995553188060297,\n",
       "  0.6723650778493557,\n",
       "  0.5510073631040561,\n",
       "  0.6406202085556565,\n",
       "  0.6501248613480581,\n",
       "  0.5033539187523578,\n",
       "  0.4743429888106587,\n",
       "  0.6369416136895452,\n",
       "  0.9166858815580153,\n",
       "  0.8940464629325691,\n",
       "  0.6413417360135685,\n",
       "  0.5788669871844455,\n",
       "  0.664285705365873,\n",
       "  0.609634618451521,\n",
       "  0.5983514724239172,\n",
       "  0.5008812412138934,\n",
       "  0.534308575045678,\n",
       "  0.6896817675628104,\n",
       "  1.0035199117376226,\n",
       "  0.7162195852865315,\n",
       "  0.4911667813536952,\n",
       "  0.4592212656492851,\n",
       "  0.938439188037723,\n",
       "  0.6561231920796103,\n",
       "  0.8962571527402932,\n",
       "  0.539277207466867,\n",
       "  0.7503743448565097,\n",
       "  0.6570922482398309,\n",
       "  0.601776493281168,\n",
       "  0.45528518512685007,\n",
       "  0.5346712560697569,\n",
       "  0.8683046679342947,\n",
       "  0.8301743163634488,\n",
       "  0.8521243677612227,\n",
       "  0.6119177972116742,\n",
       "  0.5042911898705278,\n",
       "  0.5373403564576211,\n",
       "  0.4086821771437137,\n",
       "  0.5089782415996515,\n",
       "  0.9465064495745379,\n",
       "  0.6076553424620327,\n",
       "  0.6103892287900397,\n",
       "  0.4417472577864139,\n",
       "  0.6124973830356379],\n",
       " 'intensity_var': [0.08167602438462873,\n",
       "  0.0366121981162875,\n",
       "  0.10129372868848102,\n",
       "  0.12265539081663882,\n",
       "  0.07789073265024284,\n",
       "  0.04602855616279106,\n",
       "  0.024643194324443608,\n",
       "  0.06208445378779844,\n",
       "  0.06688782830995617,\n",
       "  0.07860563599374715,\n",
       "  0.04909027742049248,\n",
       "  0.06340565576053574,\n",
       "  0.04128079304212469,\n",
       "  0.08809685521820636,\n",
       "  0.038314029662787234,\n",
       "  0.037694607681184274,\n",
       "  0.049072601374762624,\n",
       "  0.1185543180687108,\n",
       "  0.10773003726610131,\n",
       "  0.10680916537262707,\n",
       "  0.03720931684604252,\n",
       "  0.1260880425142974,\n",
       "  0.17511793152659164,\n",
       "  0.02889459233856387,\n",
       "  0.04003146106062477,\n",
       "  0.06314412617556601,\n",
       "  0.05221174306913019,\n",
       "  0.2282961118809978,\n",
       "  0.12128004747747742,\n",
       "  0.033377803810749125,\n",
       "  0.026260103325529513,\n",
       "  0.1021085308304819,\n",
       "  0.060613507616184614,\n",
       "  0.1495630754291611,\n",
       "  0.046707588651919624,\n",
       "  0.16297290151328606,\n",
       "  0.03290081971153177,\n",
       "  0.08770589636783996,\n",
       "  0.022918745205553172,\n",
       "  0.015708428949045516,\n",
       "  0.11257181651498552,\n",
       "  0.03591810972017661,\n",
       "  0.21601595842152385,\n",
       "  0.07949713561642319,\n",
       "  0.05349232250032779,\n",
       "  0.04956230290699168,\n",
       "  0.018139154613003198,\n",
       "  0.03437183639374632,\n",
       "  0.0949785698018955,\n",
       "  0.056745492775045474,\n",
       "  0.06533501574393073,\n",
       "  0.011806904632917706,\n",
       "  0.03876029382963392],\n",
       " 'intensity_cumulative': [7.214668335453169,\n",
       "  2.7972002952329653,\n",
       "  23.648483337894692,\n",
       "  16.791883160991013,\n",
       "  6.762029524772405,\n",
       "  7.951779826994883,\n",
       "  2.629057361233631,\n",
       "  3.8405544527115296,\n",
       "  15.704606210031859,\n",
       "  4.196887231642208,\n",
       "  6.723650778493557,\n",
       "  3.3060441786243366,\n",
       "  5.124961668445252,\n",
       "  10.40199778156893,\n",
       "  3.0201235125141466,\n",
       "  4.269086899295928,\n",
       "  10.191065819032723,\n",
       "  17.41703174960229,\n",
       "  38.44399790610047,\n",
       "  21.80561902446133,\n",
       "  16.208275641164473,\n",
       "  17.93571404487857,\n",
       "  15.240865461288024,\n",
       "  2.9917573621195857,\n",
       "  4.0070499297111475,\n",
       "  5.34308575045678,\n",
       "  6.207135908065293,\n",
       "  211.74270137663837,\n",
       "  38.6758576054727,\n",
       "  4.420501032183257,\n",
       "  2.7553275938957107,\n",
       "  16.891905384679013,\n",
       "  6.561231920796104,\n",
       "  33.161514651390846,\n",
       "  4.314217659734936,\n",
       "  7.503743448565096,\n",
       "  3.9425534894389855,\n",
       "  69.20429672733432,\n",
       "  2.7317111107611005,\n",
       "  3.742698792488298,\n",
       "  17.366093358685895,\n",
       "  19.094009276359323,\n",
       "  114.18466528000384,\n",
       "  6.119177972116741,\n",
       "  2.5214559493526387,\n",
       "  4.298722851660969,\n",
       "  2.0434108857185684,\n",
       "  3.562847691197561,\n",
       "  16.090609642767145,\n",
       "  40.712907944956186,\n",
       "  9.766227660640634,\n",
       "  3.533978062291311,\n",
       "  9.187460745534569],\n",
       " 'intensity_max_relThresh': [0.2899151586717217,\n",
       "  0.13142466391285978,\n",
       "  0.397635613718343,\n",
       "  0.3698809962118794,\n",
       "  0.23711167612383832,\n",
       "  0.2405222123669084,\n",
       "  0.07660188367290388,\n",
       "  0.19446186557892986,\n",
       "  0.3188892610611411,\n",
       "  0.23560297566075405,\n",
       "  0.2100944949734611,\n",
       "  0.21385314695296387,\n",
       "  0.06806456658148718,\n",
       "  0.33535943185129113,\n",
       "  0.11414898903139203,\n",
       "  0.15209407806396413,\n",
       "  0.1803035613029209,\n",
       "  0.41088689373385634,\n",
       "  0.4311630249023466,\n",
       "  0.33161276540448625,\n",
       "  0.12939763222971123,\n",
       "  0.474067201922022,\n",
       "  0.5403996006135081,\n",
       "  0.1505729306128636,\n",
       "  0.13459840589954197,\n",
       "  0.21555954102546693,\n",
       "  0.2071414270708729,\n",
       "  0.7996718622023096,\n",
       "  0.3722139604629966,\n",
       "  0.12201805114746023,\n",
       "  0.10157673743463036,\n",
       "  0.35227651903706914,\n",
       "  0.23360971020114718,\n",
       "  0.42202732947565025,\n",
       "  0.15036541108162638,\n",
       "  0.47446394889585264,\n",
       "  0.1473769034108834,\n",
       "  0.3473899902836024,\n",
       "  0.08126217011482595,\n",
       "  0.05972091920913769,\n",
       "  0.31094671680081376,\n",
       "  0.13192451846215292,\n",
       "  0.6521699843868198,\n",
       "  0.27254766648815476,\n",
       "  0.1363851424186464,\n",
       "  0.18254876905872308,\n",
       "  0.05928254281321799,\n",
       "  0.09527170735020718,\n",
       "  0.43501350648941894,\n",
       "  0.19599771191996496,\n",
       "  0.14304465632284646,\n",
       "  0.04076410108997308,\n",
       "  0.12507951797977057],\n",
       " 'intensity_mean_relThresh': [0.18442468950825616,\n",
       "  0.07608202903501038,\n",
       "  0.18772710495689374,\n",
       "  0.15409259512169954,\n",
       "  0.1277032113844374,\n",
       "  0.13645195736186994,\n",
       "  0.026973307004541997,\n",
       "  0.0922609636860523,\n",
       "  0.17719137130245297,\n",
       "  0.13348514187720692,\n",
       "  0.13777380974062367,\n",
       "  0.13704285980552436,\n",
       "  0.03686045985068587,\n",
       "  0.20864384712711392,\n",
       "  0.0617803768445088,\n",
       "  0.08758780024812414,\n",
       "  0.13864315902033186,\n",
       "  0.19100120978363522,\n",
       "  0.25376029018165036,\n",
       "  0.11713398330804642,\n",
       "  0.048718068127255494,\n",
       "  0.24790847008088834,\n",
       "  0.19238769605082937,\n",
       "  0.11063388824462309,\n",
       "  0.07286256436379057,\n",
       "  0.13324220903457978,\n",
       "  0.15489213389735607,\n",
       "  0.47473003178666484,\n",
       "  0.18899604519350433,\n",
       "  0.06707709527784939,\n",
       "  0.0615753091791594,\n",
       "  0.21498061491170084,\n",
       "  0.1326867694239521,\n",
       "  0.1589182304109615,\n",
       "  0.07829631451637686,\n",
       "  0.26905867176670845,\n",
       "  0.0807221945895975,\n",
       "  0.1695419583313934,\n",
       "  0.04576266299012074,\n",
       "  0.04478161104263277,\n",
       "  0.17143407206381625,\n",
       "  0.08641268635197426,\n",
       "  0.3195737129802836,\n",
       "  0.17087403020551015,\n",
       "  0.06580158725861693,\n",
       "  0.11437481218768841,\n",
       "  0.030751356309467327,\n",
       "  0.049911570219401416,\n",
       "  0.24313040666381228,\n",
       "  0.10057163624219621,\n",
       "  0.07036189609958043,\n",
       "  0.01915819106563532,\n",
       "  0.06666949364446377],\n",
       " 'intensity_var_relThresh': [0.08000648180281277,\n",
       "  0.03634815144998261,\n",
       "  0.10057465268735902,\n",
       "  0.11793040214450946,\n",
       "  0.08224106871859502,\n",
       "  0.052039049515325515,\n",
       "  0.0238434300681557,\n",
       "  0.059017190245000704,\n",
       "  0.05945392678322037,\n",
       "  0.07585365585613019,\n",
       "  0.04865397060339575,\n",
       "  0.06658188854987028,\n",
       "  0.027518991943145183,\n",
       "  0.08916289087474487,\n",
       "  0.037668997162405946,\n",
       "  0.03472557501293135,\n",
       "  0.0460568060824752,\n",
       "  0.10490333125403324,\n",
       "  0.1455409480554885,\n",
       "  0.10060337934563765,\n",
       "  0.03214713608363716,\n",
       "  0.1275032692608029,\n",
       "  0.17044931142697908,\n",
       "  0.026256038514728595,\n",
       "  0.04078064566361632,\n",
       "  0.06548622908672518,\n",
       "  0.05202966667267498,\n",
       "  0.20720693316038505,\n",
       "  0.10455020873144573,\n",
       "  0.03528443798449032,\n",
       "  0.026202184496577362,\n",
       "  0.100605791935898,\n",
       "  0.06324302618303249,\n",
       "  0.13314133351544222,\n",
       "  0.04641873843589591,\n",
       "  0.16423482945610957,\n",
       "  0.04574872711206605,\n",
       "  0.08089507865056843,\n",
       "  0.02334608015687731,\n",
       "  0.01639518806743064,\n",
       "  0.0766744965238093,\n",
       "  0.041121280934015,\n",
       "  0.22702996224801844,\n",
       "  0.08096019018218305,\n",
       "  0.05349651747033889,\n",
       "  0.05024668504044531,\n",
       "  0.018708868236284797,\n",
       "  0.02871104161740859,\n",
       "  0.12462342879509507,\n",
       "  0.04616830056301437,\n",
       "  0.0541694714770796,\n",
       "  0.01218452490552525,\n",
       "  0.03597750359013603],\n",
       " 'intensity_cumulative_relThresh': [2.0286715845908176,\n",
       "  0.3804101451750519,\n",
       "  7.321357093318856,\n",
       "  4.006407473164188,\n",
       "  1.0216256910754993,\n",
       "  1.7738754457043093,\n",
       "  0.161839842027252,\n",
       "  0.7380877094884184,\n",
       "  4.78416702516623,\n",
       "  0.9343959931404484,\n",
       "  1.3777380974062368,\n",
       "  0.8222571588331462,\n",
       "  0.29488367880548694,\n",
       "  3.338301554033823,\n",
       "  0.3706822610670528,\n",
       "  0.7882902022331173,\n",
       "  2.21829054432531,\n",
       "  3.629022985889069,\n",
       "  10.911692477810966,\n",
       "  3.9825554324735783,\n",
       "  1.3641059075631539,\n",
       "  6.693528692183985,\n",
       "  4.809692401270734,\n",
       "  0.5531694412231154,\n",
       "  0.5829005149103246,\n",
       "  1.3324220903457977,\n",
       "  1.3940292050762046,\n",
       "  100.16803670698629,\n",
       "  10.205786440449234,\n",
       "  0.6036938575006445,\n",
       "  0.36945185507495637,\n",
       "  3.869651068410615,\n",
       "  1.326867694239521,\n",
       "  5.879974525205576,\n",
       "  0.6263705161310149,\n",
       "  2.6905867176670846,\n",
       "  0.48433316753758504,\n",
       "  19.49732520811024,\n",
       "  0.2745759779407244,\n",
       "  0.3134712772984294,\n",
       "  3.428681441276325,\n",
       "  1.9874917860954078,\n",
       "  42.822877539358004,\n",
       "  1.7087403020551015,\n",
       "  0.32900793629308467,\n",
       "  0.9149984975015073,\n",
       "  0.15375678154733663,\n",
       "  0.3493809915358099,\n",
       "  4.133216913284809,\n",
       "  6.738299628227146,\n",
       "  1.125790337593287,\n",
       "  0.15326552852508257,\n",
       "  1.0000424046669565],\n",
       " 'intensity_max_abs': [24.029123,\n",
       "  24.709673,\n",
       "  23.513649,\n",
       "  24.68209,\n",
       "  27.001074,\n",
       "  26.82839,\n",
       "  22.627678,\n",
       "  22.496199,\n",
       "  22.745537,\n",
       "  23.900557,\n",
       "  26.127222,\n",
       "  23.238588,\n",
       "  26.91766,\n",
       "  23.538506,\n",
       "  23.468695,\n",
       "  22.457544,\n",
       "  24.345545,\n",
       "  26.506,\n",
       "  27.275003,\n",
       "  26.278267,\n",
       "  24.448092,\n",
       "  22.959042,\n",
       "  23.307371,\n",
       "  24.53752,\n",
       "  22.973381,\n",
       "  22.575424,\n",
       "  26.270006,\n",
       "  26.535255,\n",
       "  25.332214,\n",
       "  22.793547,\n",
       "  22.44467,\n",
       "  27.142513,\n",
       "  27.025887,\n",
       "  27.00342,\n",
       "  26.75111,\n",
       "  25.203604,\n",
       "  26.973,\n",
       "  22.817957,\n",
       "  22.579494,\n",
       "  24.334345,\n",
       "  26.5325,\n",
       "  26.587423,\n",
       "  27.502941,\n",
       "  23.534124,\n",
       "  23.103235,\n",
       "  22.922682,\n",
       "  22.34231,\n",
       "  23.760225,\n",
       "  26.170597,\n",
       "  25.506474,\n",
       "  24.898308,\n",
       "  22.780897,\n",
       "  25.049793],\n",
       " 'intensity_mean_abs': [23.853174,\n",
       "  24.654072,\n",
       "  22.99658,\n",
       "  24.220762,\n",
       "  26.87056,\n",
       "  26.69412,\n",
       "  22.551888,\n",
       "  22.389053,\n",
       "  22.574703,\n",
       "  23.763712,\n",
       "  26.097137,\n",
       "  23.177963,\n",
       "  26.8783,\n",
       "  23.404722,\n",
       "  23.369959,\n",
       "  22.383003,\n",
       "  24.1307,\n",
       "  26.27338,\n",
       "  27.017143,\n",
       "  26.193018,\n",
       "  24.52738,\n",
       "  22.730955,\n",
       "  23.007227,\n",
       "  24.535147,\n",
       "  22.89989,\n",
       "  22.492928,\n",
       "  26.187359,\n",
       "  25.433811,\n",
       "  24.98402,\n",
       "  22.700397,\n",
       "  22.395487,\n",
       "  26.937094,\n",
       "  26.93302,\n",
       "  26.541351,\n",
       "  26.69672,\n",
       "  24.903337,\n",
       "  26.91355,\n",
       "  23.109005,\n",
       "  22.537107,\n",
       "  24.431839,\n",
       "  26.104092,\n",
       "  26.315266,\n",
       "  26.145168,\n",
       "  23.420639,\n",
       "  23.032755,\n",
       "  22.84427,\n",
       "  22.31487,\n",
       "  23.61095,\n",
       "  26.200556,\n",
       "  26.267311,\n",
       "  24.592026,\n",
       "  22.703882,\n",
       "  25.063023],\n",
       " 'intensity_var_abs': [0.14443198,\n",
       "  0.059093717,\n",
       "  0.3247625,\n",
       "  0.37573504,\n",
       "  0.09843947,\n",
       "  0.09127724,\n",
       "  0.04423049,\n",
       "  0.062981494,\n",
       "  0.12652539,\n",
       "  0.1195496,\n",
       "  0.08548608,\n",
       "  0.061214156,\n",
       "  0.03029154,\n",
       "  0.17185454,\n",
       "  0.07697836,\n",
       "  0.038843047,\n",
       "  0.16652775,\n",
       "  0.25418034,\n",
       "  0.21142218,\n",
       "  0.26408625,\n",
       "  0.29253194,\n",
       "  0.11310538,\n",
       "  0.19899043,\n",
       "  0.032906342,\n",
       "  0.06751337,\n",
       "  0.06307731,\n",
       "  0.104621924,\n",
       "  1.7213576,\n",
       "  0.5759682,\n",
       "  0.07729316,\n",
       "  0.029614609,\n",
       "  0.1377472,\n",
       "  0.062510274,\n",
       "  0.41065708,\n",
       "  0.050892793,\n",
       "  0.24808007,\n",
       "  0.03994707,\n",
       "  0.66614157,\n",
       "  0.035949912,\n",
       "  0.08049659,\n",
       "  0.29776207,\n",
       "  0.22704962,\n",
       "  1.1225864,\n",
       "  0.09097659,\n",
       "  0.060622092,\n",
       "  0.075599454,\n",
       "  0.018051432,\n",
       "  0.093795866,\n",
       "  0.14026372,\n",
       "  0.44094706,\n",
       "  0.21458474,\n",
       "  0.05810291,\n",
       "  0.13505118],\n",
       " 'intensity_cumulative_abs': [262.38492,\n",
       "  123.270355,\n",
       "  896.86664,\n",
       "  629.7398,\n",
       "  214.96448,\n",
       "  347.02356,\n",
       "  135.31133,\n",
       "  179.11243,\n",
       "  609.51697,\n",
       "  166.34598,\n",
       "  260.97137,\n",
       "  139.06778,\n",
       "  215.0264,\n",
       "  374.47556,\n",
       "  140.21976,\n",
       "  201.44702,\n",
       "  386.0912,\n",
       "  499.1942,\n",
       "  1161.7372,\n",
       "  890.5626,\n",
       "  686.76666,\n",
       "  613.7358,\n",
       "  575.18066,\n",
       "  122.675735,\n",
       "  183.19913,\n",
       "  224.92928,\n",
       "  235.68623,\n",
       "  5366.534,\n",
       "  1349.1371,\n",
       "  204.30357,\n",
       "  134.37292,\n",
       "  484.86768,\n",
       "  269.3302,\n",
       "  982.03,\n",
       "  213.57376,\n",
       "  249.03337,\n",
       "  161.4813,\n",
       "  2657.5356,\n",
       "  135.22264,\n",
       "  171.02287,\n",
       "  522.08185,\n",
       "  605.2511,\n",
       "  3503.4526,\n",
       "  234.20639,\n",
       "  115.16377,\n",
       "  182.75417,\n",
       "  111.574356,\n",
       "  165.27666,\n",
       "  445.40945,\n",
       "  1759.9098,\n",
       "  393.4724,\n",
       "  181.63106,\n",
       "  375.94534],\n",
       " 'category': ['Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Strong',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Strong',\n",
       "  'Strong',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Strong',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Strong',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate',\n",
       "  'Moderate'],\n",
       " 'rate_onset': [0.04689838450442044,\n",
       "  0.049154170866938074,\n",
       "  0.013889998064443559,\n",
       "  0.02109038050851061,\n",
       "  0.03910176565220589,\n",
       "  0.049798329671222774,\n",
       "  0.02207818937130747,\n",
       "  0.08953009574643858,\n",
       "  0.018797045589042938,\n",
       "  0.06626566678392444,\n",
       "  0.03551922838386135,\n",
       "  0.06868183997369641,\n",
       "  0.04094084462811907,\n",
       "  0.04243440115323646,\n",
       "  0.07361773008940986,\n",
       "  0.10736680799914684,\n",
       "  0.014344329833983949,\n",
       "  0.0513829197260236,\n",
       "  0.015201900565168168,\n",
       "  0.017001188271361736,\n",
       "  0.007422276757131558,\n",
       "  0.03874133448446912,\n",
       "  0.05003575209282135,\n",
       "  0.07357289714198008,\n",
       "  0.03644646147978493,\n",
       "  0.0466562018172279,\n",
       "  0.04551718751406243,\n",
       "  0.009110354692067113,\n",
       "  0.016604250562660954,\n",
       "  0.04066371302450733,\n",
       "  0.065927628547918,\n",
       "  0.024052468394435356,\n",
       "  0.032139179428517156,\n",
       "  0.02326730480730827,\n",
       "  0.030167179722938444,\n",
       "  0.0649813867384393,\n",
       "  0.022990565146169928,\n",
       "  0.0036291253901489903,\n",
       "  0.022931217597925775,\n",
       "  0.05714804126369799,\n",
       "  0.028595104944671094,\n",
       "  0.012391562395930781,\n",
       "  0.05491061291203908,\n",
       "  0.061040263022145304,\n",
       "  0.06308601133284952,\n",
       "  0.046891717866817624,\n",
       "  0.016799223587809258,\n",
       "  0.023463123785354593,\n",
       "  0.11761488672775197,\n",
       "  0.0037210130131104715,\n",
       "  0.07099998638194076,\n",
       "  0.04102895593130166,\n",
       "  0.017429526673917495],\n",
       " 'rate_decline': [0.07975949230281897,\n",
       "  0.059457225184286956,\n",
       "  0.057705001263110706,\n",
       "  0.05243070900587964,\n",
       "  0.14113715387159687,\n",
       "  0.024189650446911813,\n",
       "  0.049607410225817716,\n",
       "  0.041411659934303006,\n",
       "  0.030494550695241616,\n",
       "  0.0900530907415579,\n",
       "  0.047903307022586716,\n",
       "  0.06282778269684185,\n",
       "  0.022156063762227906,\n",
       "  0.04715432342587178,\n",
       "  0.039384725700568564,\n",
       "  0.03116937042564416,\n",
       "  0.05773648908061497,\n",
       "  0.03909407649663596,\n",
       "  0.02774950157674911,\n",
       "  0.03144240947792878,\n",
       "  0.019731421219675537,\n",
       "  0.031091853429265934,\n",
       "  0.03870147433508979,\n",
       "  0.03820057178971784,\n",
       "  0.029314690593322566,\n",
       "  0.037648561762923353,\n",
       "  0.03574626396828054,\n",
       "  0.009531649781293602,\n",
       "  0.014712977763389335,\n",
       "  0.017036196611655077,\n",
       "  0.02117767470711919,\n",
       "  0.09284200634153095,\n",
       "  0.07099634161742786,\n",
       "  0.03178458629685637,\n",
       "  0.06355576053742382,\n",
       "  0.17473276199833024,\n",
       "  0.08499664388677175,\n",
       "  0.007760752772913002,\n",
       "  0.02859206661101297,\n",
       "  0.00793950196826916,\n",
       "  0.08389049301499034,\n",
       "  0.01968540404199456,\n",
       "  0.006639055130265961,\n",
       "  0.040276569355267355,\n",
       "  0.05765213504914328,\n",
       "  0.037453736882910725,\n",
       "  0.05782414508122121,\n",
       "  0.10099275650516759,\n",
       "  0.026266348689545457,\n",
       "  0.05824719090615531,\n",
       "  0.014059325611763237,\n",
       "  0.007894468662461062,\n",
       "  0.019140254717068927],\n",
       " 'n_events': 53}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhws, clim = detect(t, sst)\n",
    "clim['thresh'].shape\n",
    "# data = clim['seas']\n",
    "mhws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "186785b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhwBlock = blockAverage(t,mhws)\n",
    "mhwBlock['intensity_var'][:].shape\n",
    "# mhwBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb957db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#春季"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eaf4d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 1\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_1 = np.datetime64('1983-11-18')\n",
    "end_date_nino_spring_clim_1 = np.datetime64('1983-11-28')\n",
    "start_index_nino_spring_clim_1 = np.where(dates == start_date_nino_spring_clim_1)[0][0]\n",
    "end_index_nino_spring_clim_1 = np.where(dates == end_date_nino_spring_clim_1)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_1 = data[start_index_nino_spring_clim_1:end_index_nino_spring_clim_1]\n",
    "target_data_nino_spring_clim_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f992c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 2\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_2 = np.datetime64('1983-12-15')\n",
    "end_date_nino_spring_clim_2 = np.datetime64('1983-12-19')\n",
    "start_index_nino_spring_clim_2 = np.where(dates == start_date_nino_spring_clim_2)[0][0]\n",
    "end_index_nino_spring_clim_2 = np.where(dates == end_date_nino_spring_clim_2)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_2 = data[start_index_nino_spring_clim_2:end_index_nino_spring_clim_2]\n",
    "target_data_nino_spring_clim_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0859b23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 3\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_3 = np.datetime64('1987-10-05')\n",
    "end_date_nino_spring_clim_3 = np.datetime64('1987-11-12')\n",
    "start_index_nino_spring_clim_3 = np.where(dates == start_date_nino_spring_clim_3)[0][0]\n",
    "end_index_nino_spring_clim_3 = np.where(dates == end_date_nino_spring_clim_3)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_3 = data[start_index_nino_spring_clim_3:end_index_nino_spring_clim_3]\n",
    "target_data_nino_spring_clim_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af460c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 4\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_4 = np.datetime64('1987-11-21')\n",
    "end_date_nino_spring_clim_4 = np.datetime64('1987-12-16')\n",
    "start_index_nino_spring_clim_4 = np.where(dates == start_date_nino_spring_clim_4)[0][0]\n",
    "end_index_nino_spring_clim_4 = np.where(dates == end_date_nino_spring_clim_4)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_4 = data[start_index_nino_spring_clim_4:end_index_nino_spring_clim_4]\n",
    "target_data_nino_spring_clim_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3141de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 7\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_5 = np.datetime64('1989-10-09')\n",
    "end_date_nino_spring_clim_5 = np.datetime64('1989-10-14')\n",
    "start_index_nino_spring_clim_5 = np.where(dates == start_date_nino_spring_clim_5)[0][0]\n",
    "end_index_nino_spring_clim_5 = np.where(dates == end_date_nino_spring_clim_5)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_5 = data[start_index_nino_spring_clim_5 : end_index_nino_spring_clim_5]\n",
    "target_data_nino_spring_clim_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b4eb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 9\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_6 = np.datetime64('1993-09-23')\n",
    "end_date_nino_spring_clim_6 = np.datetime64('1993-10-14')\n",
    "start_index_nino_spring_clim_6 = np.where(dates == start_date_nino_spring_clim_6)[0][0]\n",
    "end_index_nino_spring_clim_6 = np.where(dates == end_date_nino_spring_clim_6)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_6 = data[start_index_nino_spring_clim_6 : end_index_nino_spring_clim_6]\n",
    "target_data_nino_spring_clim_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b8b466b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 10\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_7 = np.datetime64('1993-11-19')\n",
    "end_date_nino_spring_clim_7 = np.datetime64('1993-11-25')\n",
    "start_index_nino_spring_clim_7 = np.where(dates == start_date_nino_spring_clim_7)[0][0]\n",
    "end_index_nino_spring_clim_7 = np.where(dates == end_date_nino_spring_clim_7)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_7 = data[start_index_nino_spring_clim_7 : end_index_nino_spring_clim_7]\n",
    "target_data_nino_spring_clim_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27375a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 12\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_8 = np.datetime64('1997-11-01')\n",
    "end_date_nino_spring_clim_8 = np.datetime64('1997-11-06')\n",
    "start_index_nino_spring_clim_8 = np.where(dates == start_date_nino_spring_clim_8)[0][0]\n",
    "end_index_nino_spring_clim_8 = np.where(dates == end_date_nino_spring_clim_8)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_8 = data[start_index_nino_spring_clim_8 : end_index_nino_spring_clim_8]\n",
    "target_data_nino_spring_clim_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42865f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 13\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_9 = np.datetime64('1998-02-25')\n",
    "end_date_nino_spring_clim_9 = np.datetime64('1998-03-04')\n",
    "start_index_nino_spring_clim_9 = np.where(dates == start_date_nino_spring_clim_9)[0][0]\n",
    "end_index_nino_spring_clim_9 = np.where(dates == end_date_nino_spring_clim_9)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_9 = data[start_index_nino_spring_clim_9 : end_index_nino_spring_clim_9]\n",
    "target_data_nino_spring_clim_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ee1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 17\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_10 = np.datetime64('2002-11-24')\n",
    "end_date_nino_spring_clim_10 = np.datetime64('2002-12-09')\n",
    "start_index_nino_spring_clim_10 = np.where(dates == start_date_nino_spring_clim_10)[0][0]\n",
    "end_index_nino_spring_clim_10 = np.where(dates == end_date_nino_spring_clim_10)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_10 = data[start_index_nino_spring_clim_10 : end_index_nino_spring_clim_10]\n",
    "target_data_nino_spring_clim_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f595c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 23\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_11 = np.datetime64('2003-10-13')\n",
    "end_date_nino_spring_clim_11 = np.datetime64('2003-11-06')\n",
    "start_index_nino_spring_clim_11 = np.where(dates == start_date_nino_spring_clim_11)[0][0]\n",
    "end_index_nino_spring_clim_11 = np.where(dates == end_date_nino_spring_clim_11)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_11 = data[start_index_nino_spring_clim_11 : end_index_nino_spring_clim_11]\n",
    "target_data_nino_spring_clim_11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8190f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 23\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_12 = np.datetime64('2003-12-11')\n",
    "end_date_nino_spring_clim_12 = np.datetime64('2003-12-15')\n",
    "start_index_nino_spring_clim_12 = np.where(dates == start_date_nino_spring_clim_12)[0][0]\n",
    "end_index_nino_spring_clim_12 = np.where(dates == end_date_nino_spring_clim_12)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_12 = data[start_index_nino_spring_clim_12 : end_index_nino_spring_clim_12]\n",
    "target_data_nino_spring_clim_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d4198c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 28\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_13 = np.datetime64('2009-09-23')\n",
    "end_date_nino_spring_clim_13 = np.datetime64('2009-12-12')\n",
    "start_index_nino_spring_clim_13 = np.where(dates == start_date_nino_spring_clim_13)[0][0]\n",
    "end_index_nino_spring_clim_13 = np.where(dates == end_date_nino_spring_clim_13)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_13 = data[start_index_nino_spring_clim_13 : end_index_nino_spring_clim_13]\n",
    "target_data_nino_spring_clim_13.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "791108d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 36\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_14 = np.datetime64('2015-12-14')\n",
    "end_date_nino_spring_clim_14 = np.datetime64('2015-12-23')\n",
    "start_index_nino_spring_clim_14 = np.where(dates == start_date_nino_spring_clim_14)[0][0]\n",
    "end_index_nino_spring_clim_14 = np.where(dates == end_date_nino_spring_clim_14)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_14 = data[start_index_nino_spring_clim_14 : end_index_nino_spring_clim_14]\n",
    "target_data_nino_spring_clim_14.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5139d964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 38\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_15 = np.datetime64('2016-09-23')\n",
    "end_date_nino_spring_clim_15 = np.datetime64('2016-10-03')\n",
    "start_index_nino_spring_clim_15 = np.where(dates == start_date_nino_spring_clim_15)[0][0]\n",
    "end_index_nino_spring_clim_15 = np.where(dates == end_date_nino_spring_clim_15)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_15 = data[start_index_nino_spring_clim_15 : end_index_nino_spring_clim_15]\n",
    "target_data_nino_spring_clim_15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d921e47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 39\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_16 = np.datetime64('2016-10-07')\n",
    "end_date_nino_spring_clim_16 = np.datetime64('2016-10-12')\n",
    "start_index_nino_spring_clim_16 = np.where(dates == start_date_nino_spring_clim_16)[0][0]\n",
    "end_index_nino_spring_clim_16 = np.where(dates == end_date_nino_spring_clim_16)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_16 = data[start_index_nino_spring_clim_16 : end_index_nino_spring_clim_16]\n",
    "target_data_nino_spring_clim_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc7c6a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 40\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_17 = np.datetime64('2016-12-09')\n",
    "end_date_nino_spring_clim_17 = np.datetime64('2016-12-15')\n",
    "start_index_nino_spring_clim_17 = np.where(dates == start_date_nino_spring_clim_17)[0][0]\n",
    "end_index_nino_spring_clim_17 = np.where(dates == end_date_nino_spring_clim_17)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_17 = data[start_index_nino_spring_clim_17 : end_index_nino_spring_clim_17]\n",
    "target_data_nino_spring_clim_17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b558b36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 48\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_spring_clim_18 = np.datetime64('2019-11-17')\n",
    "end_date_nino_spring_clim_18 = np.datetime64('2019-11-23')\n",
    "start_index_nino_spring_clim_18 = np.where(dates == start_date_nino_spring_clim_18)[0][0]\n",
    "end_index_nino_spring_clim_18 = np.where(dates == end_date_nino_spring_clim_18)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_spring_clim_18 = data[start_index_nino_spring_clim_18 : end_index_nino_spring_clim_18]\n",
    "target_data_nino_spring_clim_18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e5b6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#夏季"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e575cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 5\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_1 = np.datetime64('1988-02-10')\n",
    "end_date_nino_summer_clim_1 = np.datetime64('1988-02-17')\n",
    "start_index_nino_summer_clim_1 = np.where(dates == start_date_nino_summer_clim_1)[0][0]\n",
    "end_index_nino_summer_clim_1 = np.where(dates == end_date_nino_summer_clim_1)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_1 = data[start_index_nino_summer_clim_1:end_index_nino_summer_clim_1]\n",
    "target_data_nino_summer_clim_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79ffaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 18\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_2 = np.datetime64('2003-01-11')\n",
    "end_date_nino_summer_clim_2 = np.datetime64('2003-01-19')\n",
    "start_index_nino_summer_clim_2 = np.where(dates == start_date_nino_summer_clim_2)[0][0]\n",
    "end_index_nino_summer_clim_2 = np.where(dates == end_date_nino_summer_clim_2)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_2 = data[start_index_nino_summer_clim_2 : end_index_nino_summer_clim_2]\n",
    "target_data_nino_summer_clim_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "709aafbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 19\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_3 = np.datetime64('2003-02-02')\n",
    "end_date_nino_summer_clim_3 = np.datetime64('2003-03-16')\n",
    "start_index_nino_summer_clim_3 = np.where(dates == start_date_nino_summer_clim_3)[0][0]\n",
    "end_index_nino_summer_clim_3 = np.where(dates == end_date_nino_summer_clim_3)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_3 = data[start_index_nino_summer_clim_3 : end_index_nino_summer_clim_3]\n",
    "target_data_nino_summer_clim_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1906869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 28\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_4 = np.datetime64('2009-12-23')\n",
    "end_date_nino_summer_clim_4 = np.datetime64('2010-03-20')\n",
    "start_index_nino_summer_clim_4 = np.where(dates == start_date_nino_summer_clim_4)[0][0]\n",
    "end_index_nino_summer_clim_4 = np.where(dates == end_date_nino_summer_clim_4)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_4 = data[start_index_nino_summer_clim_4 : end_index_nino_summer_clim_4]\n",
    "target_data_nino_summer_clim_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "372888c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 32\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_5 = np.datetime64('2014-02-04')\n",
    "end_date_nino_summer_clim_5 = np.datetime64('2014-02-21')\n",
    "start_index_nino_summer_clim_5 = np.where(dates == start_date_nino_summer_clim_5)[0][0]\n",
    "end_index_nino_summer_clim_5 = np.where(dates == end_date_nino_summer_clim_5)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_5 = data[start_index_nino_summer_clim_5 : end_index_nino_summer_clim_5]\n",
    "target_data_nino_summer_clim_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0415c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 32\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_6 = np.datetime64('2014-02-04')\n",
    "end_date_nino_summer_clim_6 = np.datetime64('2014-02-21')\n",
    "start_index_nino_summer_clim_6 = np.where(dates == start_date_nino_summer_clim_6)[0][0]\n",
    "end_index_nino_summer_clim_6 = np.where(dates == end_date_nino_summer_clim_6)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_6 = data[start_index_nino_summer_clim_6 : end_index_nino_summer_clim_6]\n",
    "target_data_nino_summer_clim_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e29e5f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 33\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_7 = np.datetime64('2014-03-04')\n",
    "end_date_nino_summer_clim_7 = np.datetime64('2014-03-13')\n",
    "start_index_nino_summer_clim_7 = np.where(dates == start_date_nino_summer_clim_7)[0][0]\n",
    "end_index_nino_summer_clim_7 = np.where(dates == end_date_nino_summer_clim_7)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_7 = data[start_index_nino_summer_clim_7 : end_index_nino_summer_clim_7]\n",
    "target_data_nino_summer_clim_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95b35793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 34\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_8 = np.datetime64('2015-01-12')\n",
    "end_date_nino_summer_clim_8 = np.datetime64('2015-02-17')\n",
    "start_index_nino_summer_clim_8 = np.where(dates == start_date_nino_summer_clim_8)[0][0]\n",
    "end_index_nino_summer_clim_8 = np.where(dates == end_date_nino_summer_clim_8)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_8 = data[start_index_nino_summer_clim_8 : end_index_nino_summer_clim_8]\n",
    "target_data_nino_summer_clim_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6ba9d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 37\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_9= np.datetime64('2016-02-29')\n",
    "end_date_nino_summer_clim_9 = np.datetime64('2016-03-05')\n",
    "start_index_nino_summer_clim_9 = np.where(dates == start_date_nino_summer_clim_9)[0][0]\n",
    "end_index_nino_summer_clim_9 = np.where(dates == end_date_nino_summer_clim_9)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_9 = data[start_index_nino_summer_clim_9 : end_index_nino_summer_clim_9]\n",
    "target_data_nino_summer_clim_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c2c8ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 41\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_10= np.datetime64('2017-01-07')\n",
    "end_date_nino_summer_clim_10 = np.datetime64('2017-01-26')\n",
    "start_index_nino_summer_clim_10 = np.where(dates == start_date_nino_summer_clim_10)[0][0]\n",
    "end_index_nino_summer_clim_10 = np.where(dates == end_date_nino_summer_clim_10)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_10 = data[start_index_nino_summer_clim_10 : end_index_nino_summer_clim_10]\n",
    "target_data_nino_summer_clim_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6a311bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 42\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_11= np.datetime64('2019-01-13')\n",
    "end_date_nino_summer_clim_11 = np.datetime64('2019-02-04')\n",
    "start_index_nino_summer_clim_11 = np.where(dates == start_date_nino_summer_clim_11)[0][0]\n",
    "end_index_nino_summer_clim_11 = np.where(dates == end_date_nino_summer_clim_11)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_11 = data[start_index_nino_summer_clim_11 : end_index_nino_summer_clim_11]\n",
    "target_data_nino_summer_clim_11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8be95f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 43\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_12= np.datetime64('2019-02-15')\n",
    "end_date_nino_summer_clim_12 = np.datetime64('2019-03-20')\n",
    "start_index_nino_summer_clim_12 = np.where(dates == start_date_nino_summer_clim_12)[0][0]\n",
    "end_index_nino_summer_clim_12 = np.where(dates == end_date_nino_summer_clim_12)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_12 = data[start_index_nino_summer_clim_12 : end_index_nino_summer_clim_12]\n",
    "target_data_nino_summer_clim_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85db6401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 49\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_13= np.datetime64('2020-01-09')\n",
    "end_date_nino_summer_clim_13 = np.datetime64('2020-01-25')\n",
    "start_index_nino_summer_clim_13 = np.where(dates == start_date_nino_summer_clim_13)[0][0]\n",
    "end_index_nino_summer_clim_13 = np.where(dates == end_date_nino_summer_clim_13)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_13 = data[start_index_nino_summer_clim_13 : end_index_nino_summer_clim_13]\n",
    "target_data_nino_summer_clim_13.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e6995b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 50\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_summer_clim_14= np.datetime64('2020-03-15')\n",
    "end_date_nino_summer_clim_14 = np.datetime64('2020-03-20')\n",
    "start_index_nino_summer_clim_14 = np.where(dates == start_date_nino_summer_clim_14)[0][0]\n",
    "end_index_nino_summer_clim_14 = np.where(dates == end_date_nino_summer_clim_14)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_summer_clim_14 = data[start_index_nino_summer_clim_14 : end_index_nino_summer_clim_14]\n",
    "target_data_nino_summer_clim_14.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8bcb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#秋季"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a5a182e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 6\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_1 = np.datetime64('1988-03-26')\n",
    "end_date_nino_autumn_clim_1 = np.datetime64('1988-04-07')\n",
    "start_index_nino_autumn_clim_1 = np.where(dates == start_date_nino_autumn_clim_1)[0][0]\n",
    "end_index_nino_autumn_clim_1 = np.where(dates == end_date_nino_autumn_clim_1)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_1 = data[start_index_nino_autumn_clim_1:end_index_nino_autumn_clim_1]\n",
    "target_data_nino_autumn_clim_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44c995eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 11\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_2 = np.datetime64('1995-04-24')\n",
    "end_date_nino_autumn_clim_2 = np.datetime64('1995-05-03')\n",
    "start_index_nino_autumn_clim_2 = np.where(dates == start_date_nino_autumn_clim_2)[0][0]\n",
    "end_index_nino_autumn_clim_2 = np.where(dates == end_date_nino_autumn_clim_2)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_2 = data[start_index_nino_autumn_clim_2:end_index_nino_autumn_clim_2]\n",
    "target_data_nino_autumn_clim_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "961979c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 20\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_3 = np.datetime64('2003-04-07')\n",
    "end_date_nino_autumn_clim_3 = np.datetime64('2003-05-10')\n",
    "start_index_nino_autumn_clim_3 = np.where(dates == start_date_nino_autumn_clim_3)[0][0]\n",
    "end_index_nino_autumn_clim_3 = np.where(dates == end_date_nino_autumn_clim_3)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_3 = data[start_index_nino_autumn_clim_3:end_index_nino_autumn_clim_3]\n",
    "target_data_nino_autumn_clim_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbe3ac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 20\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_4 = np.datetime64('2003-05-28')\n",
    "end_date_nino_autumn_clim_4 = np.datetime64('2003-06-22')\n",
    "start_index_nino_autumn_clim_4 = np.where(dates == start_date_nino_autumn_clim_4)[0][0]\n",
    "end_index_nino_autumn_clim_4 = np.where(dates == end_date_nino_autumn_clim_4)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_4 = data[start_index_nino_autumn_clim_4 : end_index_nino_autumn_clim_4]\n",
    "target_data_nino_autumn_clim_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16a61700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 20\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_5 = np.datetime64('2008-04-22')\n",
    "end_date_nino_autumn_clim_5 = np.datetime64('2008-04-30')\n",
    "start_index_nino_autumn_clim_5 = np.where(dates == start_date_nino_autumn_clim_5)[0][0]\n",
    "end_index_nino_autumn_clim_5 = np.where(dates == end_date_nino_autumn_clim_5)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_5 = data[start_index_nino_autumn_clim_5 : end_index_nino_autumn_clim_5]\n",
    "target_data_nino_autumn_clim_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cdf5805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 20\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_6 = np.datetime64('2008-04-22')\n",
    "end_date_nino_autumn_clim_6 = np.datetime64('2008-04-30')\n",
    "start_index_nino_autumn_clim_6 = np.where(dates == start_date_nino_autumn_clim_6)[0][0]\n",
    "end_index_nino_autumn_clim_6 = np.where(dates == end_date_nino_autumn_clim_6)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_6 = data[start_index_nino_autumn_clim_6 : end_index_nino_autumn_clim_6]\n",
    "target_data_nino_autumn_clim_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "287b8afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 28\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_7 = np.datetime64('2010-03-21')\n",
    "end_date_nino_autumn_clim_7 = np.datetime64('2010-04-18')\n",
    "start_index_nino_autumn_clim_7 = np.where(dates == start_date_nino_autumn_clim_7)[0][0]\n",
    "end_index_nino_autumn_clim_7 = np.where(dates == end_date_nino_autumn_clim_7)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_7 = data[start_index_nino_autumn_clim_7 : end_index_nino_autumn_clim_7]\n",
    "target_data_nino_autumn_clim_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cca4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 29\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_8 = np.datetime64('2010-05-06')\n",
    "end_date_nino_autumn_clim_8 = np.datetime64('2010-06-22')\n",
    "start_index_nino_autumn_clim_8 = np.where(dates == start_date_nino_autumn_clim_8)[0][0]\n",
    "end_index_nino_autumn_clim_8 = np.where(dates == end_date_nino_autumn_clim_8)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_8 = data[start_index_nino_autumn_clim_8 : end_index_nino_autumn_clim_8]\n",
    "target_data_nino_autumn_clim_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0e6c295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 35\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_9 = np.datetime64('2015-03-24')\n",
    "end_date_nino_autumn_clim_9 = np.datetime64('2015-03-31')\n",
    "start_index_nino_autumn_clim_9 = np.where(dates == start_date_nino_autumn_clim_9)[0][0]\n",
    "end_index_nino_autumn_clim_9 = np.where(dates == end_date_nino_autumn_clim_9)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_9 = data[start_index_nino_autumn_clim_9 : end_index_nino_autumn_clim_9]\n",
    "target_data_nino_autumn_clim_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22faea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 38\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_10 = np.datetime64('2016-06-11')\n",
    "end_date_nino_autumn_clim_10 = np.datetime64('2016-06-22')\n",
    "start_index_nino_autumn_clim_10 = np.where(dates == start_date_nino_autumn_clim_10)[0][0]\n",
    "end_index_nino_autumn_clim_10 = np.where(dates == end_date_nino_autumn_clim_10)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_10 = data[start_index_nino_autumn_clim_10 : end_index_nino_autumn_clim_10]\n",
    "target_data_nino_autumn_clim_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42c98586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 43\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_11 = np.datetime64('2019-03-21')\n",
    "end_date_nino_autumn_clim_11 = np.datetime64('2019-06-22')\n",
    "start_index_nino_autumn_clim_11 = np.where(dates == start_date_nino_autumn_clim_11)[0][0]\n",
    "end_index_nino_autumn_clim_11 = np.where(dates == end_date_nino_autumn_clim_11)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_11 = data[start_index_nino_autumn_clim_11 : end_index_nino_autumn_clim_11]\n",
    "target_data_nino_autumn_clim_11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "639ec72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 50\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_12 = np.datetime64('2020-03-21')\n",
    "end_date_nino_autumn_clim_12 = np.datetime64('2020-05-20')\n",
    "start_index_nino_autumn_clim_12 = np.where(dates == start_date_nino_autumn_clim_12)[0][0]\n",
    "end_index_nino_autumn_clim_12 = np.where(dates == end_date_nino_autumn_clim_12)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_12 = data[start_index_nino_autumn_clim_12 : end_index_nino_autumn_clim_12]\n",
    "target_data_nino_autumn_clim_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "708c07c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 51\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_13 = np.datetime64('2020-06-02')\n",
    "end_date_nino_autumn_clim_13 = np.datetime64('2020-06-07')\n",
    "start_index_nino_autumn_clim_13 = np.where(dates == start_date_nino_autumn_clim_13)[0][0]\n",
    "end_index_nino_autumn_clim_13 = np.where(dates == end_date_nino_autumn_clim_13)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_13 = data[start_index_nino_autumn_clim_13 : end_index_nino_autumn_clim_13]\n",
    "target_data_nino_autumn_clim_13.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ccc7939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 53\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_autumn_clim_14 = np.datetime64('2021-05-20')\n",
    "end_date_nino_autumn_clim_14 = np.datetime64('2021-06-03')\n",
    "start_index_nino_autumn_clim_14 = np.where(dates == start_date_nino_autumn_clim_14)[0][0]\n",
    "end_index_nino_autumn_clim_14 = np.where(dates == end_date_nino_autumn_clim_14)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_autumn_clim_14 = data[start_index_nino_autumn_clim_14 : end_index_nino_autumn_clim_14]\n",
    "target_data_nino_autumn_clim_14.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "040fc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#冬季"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83abc066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 8\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_1 = np.datetime64('1993-09-05')\n",
    "end_date_nino_winter_clim_1 = np.datetime64('1993-09-12')\n",
    "start_index_nino_winter_clim_1 = np.where(dates == start_date_nino_winter_clim_1)[0][0]\n",
    "end_index_nino_winter_clim_1 = np.where(dates == end_date_nino_winter_clim_1)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_1 = data[start_index_nino_winter_clim_1:end_index_nino_winter_clim_1]\n",
    "target_data_nino_winter_clim_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a9d6e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 8\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_2 = np.datetime64('1993-09-18')\n",
    "end_date_nino_winter_clim_2 = np.datetime64('1993-09-22')\n",
    "start_index_nino_winter_clim_2 = np.where(dates == start_date_nino_winter_clim_2)[0][0]\n",
    "end_index_nino_winter_clim_2 = np.where(dates == end_date_nino_winter_clim_2)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_2 = data[start_index_nino_winter_clim_2:end_index_nino_winter_clim_2]\n",
    "target_data_nino_winter_clim_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c7303602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 14\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_3 = np.datetime64('1998-07-10')\n",
    "end_date_nino_winter_clim_3 = np.datetime64('1998-07-25')\n",
    "start_index_nino_winter_clim_3 = np.where(dates == start_date_nino_winter_clim_3)[0][0]\n",
    "end_index_nino_winter_clim_3 = np.where(dates == end_date_nino_winter_clim_3)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_3 = data[start_index_nino_winter_clim_3:end_index_nino_winter_clim_3]\n",
    "target_data_nino_winter_clim_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f59cf7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 15\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_4 = np.datetime64('2002-07-11')\n",
    "end_date_nino_winter_clim_4 = np.datetime64('2002-07-16')\n",
    "start_index_nino_winter_clim_4 = np.where(dates == start_date_nino_winter_clim_4)[0][0]\n",
    "end_index_nino_winter_clim_4 = np.where(dates == end_date_nino_winter_clim_4)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_4 = data[start_index_nino_winter_clim_4:end_index_nino_winter_clim_4]\n",
    "target_data_nino_winter_clim_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "543198bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 16\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_5 = np.datetime64('2002-09-05')\n",
    "end_date_nino_winter_clim_5 = np.datetime64('2002-09-13')\n",
    "start_index_nino_winter_clim_5 = np.where(dates == start_date_nino_winter_clim_5)[0][0]\n",
    "end_index_nino_winter_clim_5 = np.where(dates == end_date_nino_winter_clim_5)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_5 = data[start_index_nino_winter_clim_5 : end_index_nino_winter_clim_5]\n",
    "target_data_nino_winter_clim_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "acb43d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 21\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_6 = np.datetime64('2003-06-23')\n",
    "end_date_nino_winter_clim_6 = np.datetime64('2003-06-24')\n",
    "start_index_nino_winter_clim_6 = np.where(dates == start_date_nino_winter_clim_6)[0][0]\n",
    "end_index_nino_winter_clim_6 = np.where(dates == end_date_nino_winter_clim_6)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_6 = data[start_index_nino_winter_clim_6 : end_index_nino_winter_clim_6]\n",
    "target_data_nino_winter_clim_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a677faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 22\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_7 = np.datetime64('2003-08-06')\n",
    "end_date_nino_winter_clim_7 = np.datetime64('2003-09-01')\n",
    "start_index_nino_winter_clim_7 = np.where(dates == start_date_nino_winter_7)[0][0]\n",
    "end_index_nino_winter_clim_7 = np.where(dates == end_date_nino_winter_7)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_7 = data[start_index_nino_winter_7 : end_index_nino_winter_7]\n",
    "target_data_nino_winter_clim_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f87abfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 25\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_8 = np.datetime64('2004-07-28')\n",
    "end_date_nino_winter_clim_8 = np.datetime64('2004-08-04')\n",
    "start_index_nino_winter_clim_8 = np.where(dates == start_date_nino_winter_clim_8)[0][0]\n",
    "end_index_nino_winter_clim_8 = np.where(dates == end_date_nino_winter_clim_8)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_8 = data[start_index_nino_winter_clim_8 : end_index_nino_winter_clim_8]\n",
    "target_data_nino_winter_clim_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c8b30c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 26\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_9 = np.datetime64('2004-08-24')\n",
    "end_date_nino_winter_clim_9 = np.datetime64('2004-09-02')\n",
    "start_index_nino_winter_clim_9 = np.where(dates == start_date_nino_winter_clim_9)[0][0]\n",
    "end_index_nino_winter_clim_9 = np.where(dates == end_date_nino_winter_clim_9)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_9 = data[start_index_nino_winter_clim_9 : end_index_nino_winter_clim_9]\n",
    "target_data_nino_winter_clim_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23cffc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 28\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_10 = np.datetime64('2009-09-20')\n",
    "end_date_nino_winter_clim_10 = np.datetime64('2009-09-22')\n",
    "start_index_nino_winter_clim_10 = np.where(dates == start_date_nino_winter_clim_10)[0][0]\n",
    "end_index_nino_winter_clim_10 = np.where(dates == end_date_nino_winter_clim_10)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_10 = data[start_index_nino_winter_clim_10 : end_index_nino_winter_clim_10]\n",
    "target_data_nino_winter_clim_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ed6c953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 29\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_11 = np.datetime64('2010-06-23')\n",
    "end_date_nino_winter_clim_11 = np.datetime64('2010-06-28')\n",
    "start_index_nino_winter_clim_11 = np.where(dates == start_date_nino_winter_clim_11)[0][0]\n",
    "end_index_nino_winter_clim_11 = np.where(dates == end_date_nino_winter_clim_11)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_11 = data[start_index_nino_winter_clim_11 : end_index_nino_winter_clim_11]\n",
    "target_data_nino_winter_clim_11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4308f8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 30\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_12 = np.datetime64('2013-08-05')\n",
    "end_date_nino_winter_clim_12 = np.datetime64('2013-08-13')\n",
    "start_index_nino_winter_clim_12 = np.where(dates == start_date_nino_winter_clim_12)[0][0]\n",
    "end_index_nino_winter_clim_12 = np.where(dates == end_date_nino_winter_clim_12)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_12 = data[start_index_nino_winter_clim_12 : end_index_nino_winter_clim_12]\n",
    "target_data_nino_winter_clim_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a4409bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 31\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_13 = np.datetime64('2013-08-29')\n",
    "end_date_nino_winter_clim_13 = np.datetime64('2013-09-03')\n",
    "start_index_nino_winter_clim_13 = np.where(dates == start_date_nino_winter_clim_13)[0][0]\n",
    "end_index_nino_winter_clim_13 = np.where(dates == end_date_nino_winter_clim_13)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_13 = data[start_index_nino_winter_clim_13 : end_index_nino_winter_clim_13]\n",
    "target_data_nino_winter_clim_13.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b9895ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 38\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_14 = np.datetime64('2016-06-23')\n",
    "end_date_nino_winter_clim_14 = np.datetime64('2016-09-22')\n",
    "start_index_nino_winter_clim_14 = np.where(dates == start_date_nino_winter_clim_14)[0][0]\n",
    "end_index_nino_winter_clim_14 = np.where(dates == end_date_nino_winter_clim_14)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_14 = data[start_index_nino_winter_clim_14 : end_index_nino_winter_clim_14]\n",
    "target_data_nino_winter_clim_14.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bb53d8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 43\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_15 = np.datetime64('2019-06-23')\n",
    "end_date_nino_winter_clim_15 = np.datetime64('2019-06-28')\n",
    "start_index_nino_winter_clim_15 = np.where(dates == start_date_nino_winter_clim_15)[0][0]\n",
    "end_index_nino_winter_clim_15 = np.where(dates == end_date_nino_winter_clim_15)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_15 = data[start_index_nino_winter_clim_15 : end_index_nino_winter_clim_15]\n",
    "target_data_nino_winter_clim_15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "04d0df62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 44\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_16 = np.datetime64('2019-07-11')\n",
    "end_date_nino_winter_clim_16 = np.datetime64('2019-07-20')\n",
    "start_index_nino_winter_clim_16 = np.where(dates == start_date_nino_winter_clim_16)[0][0]\n",
    "end_index_nino_winter_clim_16 = np.where(dates == end_date_nino_winter_clim_16)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_16 = data[start_index_nino_winter_clim_16 : end_index_nino_winter_clim_16]\n",
    "target_data_nino_winter_clim_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06a3b913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 45\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_17 = np.datetime64('2019-07-24')\n",
    "end_date_nino_winter_clim_17 = np.datetime64('2019-07-28')\n",
    "start_index_nino_winter_clim_17 = np.where(dates == start_date_nino_winter_clim_17)[0][0]\n",
    "end_index_nino_winter_clim_17 = np.where(dates == end_date_nino_winter_clim_17)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_17 = data[start_index_nino_winter_clim_17 : end_index_nino_winter_clim_17]\n",
    "target_data_nino_winter_clim_17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "79f9bb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 46\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_18 = np.datetime64('2019-08-01')\n",
    "end_date_nino_winter_clim_18 = np.datetime64('2019-08-08')\n",
    "start_index_nino_winter_clim_18 = np.where(dates == start_date_nino_winter_clim_18)[0][0]\n",
    "end_index_nino_winter_clim_18 = np.where(dates == end_date_nino_winter_clim_18)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_18 = data[start_index_nino_winter_clim_18 : end_index_nino_winter_clim_18]\n",
    "target_data_nino_winter_clim_18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "179e29b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 47\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_19 = np.datetime64('2019-09-12')\n",
    "end_date_nino_winter_clim_19 = np.datetime64('2019-09-16')\n",
    "start_index_nino_winter_clim_19 = np.where(dates == start_date_nino_winter_clim_19)[0][0]\n",
    "end_index_nino_winter_clim_19 = np.where(dates == end_date_nino_winter_clim_19)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_19 = data[start_index_nino_winter_clim_19 : end_index_nino_winter_clim_19]\n",
    "target_data_nino_winter_clim_19.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0686f56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_event --- > 52\n",
    "start_date = np.datetime64('1982-01-01')\n",
    "dates = start_date + np.arange(14610) * np.timedelta64(1, 'D')\n",
    "\n",
    "# 选择特定日期范围的数据\n",
    "start_date_nino_winter_clim_20 = np.datetime64('2020-08-03')\n",
    "end_date_nino_winter_clim_20 = np.datetime64('2020-08-10')\n",
    "start_index_nino_winter_clim_20 = np.where(dates == start_date_nino_winter_clim_20)[0][0]\n",
    "end_index_nino_winter_clim_20 = np.where(dates == end_date_nino_winter_clim_20)[0][0] + 1  # 注意要加 1，因为切片时 end_index 是开区间\n",
    "target_data_nino_winter_clim_20 = data[start_index_nino_winter_clim_20 : end_index_nino_winter_clim_20]\n",
    "target_data_nino_winter_clim_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cbb29e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(r'D:\\heat_wave\\atlantic\\Nino_spring_summer_autumn_winter_imshow\\heat_wave_spring_clim.npz',\n",
    "        target_data_nino_spring_clim_1 = target_data_nino_spring_clim_1, target_data_nino_spring_clim_2 = target_data_nino_spring_clim_2,\n",
    "        target_data_nino_spring_clim_3 = target_data_nino_spring_clim_3, target_data_nino_spring_clim_4 = target_data_nino_spring_clim_4,\n",
    "        target_data_nino_spring_clim_5 = target_data_nino_spring_clim_5, target_data_nino_spring_clim_6 = target_data_nino_spring_clim_6,\n",
    "        target_data_nino_spring_clim_7 = target_data_nino_spring_clim_7, target_data_nino_spring_clim_8 = target_data_nino_spring_clim_8,\n",
    "        target_data_nino_spring_clim_9 = target_data_nino_spring_clim_9, target_data_nino_spring_clim_10 = target_data_nino_spring_clim_10,\n",
    "        target_data_nino_spring_clim_11 = target_data_nino_spring_clim_11, target_data_nino_spring_clim_12 = target_data_nino_spring_clim_12,\n",
    "        target_data_nino_spring_clim_13 = target_data_nino_spring_clim_13, target_data_nino_spring_clim_14 = target_data_nino_spring_clim_14,\n",
    "        target_data_nino_spring_clim_15 = target_data_nino_spring_clim_15, target_data_nino_spring_clim_16 = target_data_nino_spring_clim_16,\n",
    "        target_data_nino_spring_clim_17 = target_data_nino_spring_clim_17, target_data_nino_spring_clim_18 = target_data_nino_spring_clim_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e973c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(r'D:\\heat_wave\\atlantic\\Nino_spring_summer_autumn_winter_imshow\\heat_wave_summer_clim.npz',\n",
    "        target_data_nino_summer_clim_1 = target_data_nino_summer_clim_1, target_data_nino_summer_clim_2 = target_data_nino_summer_clim_2,\n",
    "        target_data_nino_summer_clim_3 = target_data_nino_summer_clim_3, target_data_nino_summer_clim_4 = target_data_nino_summer_clim_4,\n",
    "        target_data_nino_summer_clim_5 = target_data_nino_summer_clim_5, target_data_nino_summer_clim_6 = target_data_nino_summer_clim_6,\n",
    "        target_data_nino_summer_clim_7 = target_data_nino_summer_clim_7, target_data_nino_summer_clim_8 = target_data_nino_summer_clim_8,\n",
    "        target_data_nino_summer_clim_9 = target_data_nino_summer_clim_9, target_data_nino_summer_clim_10 = target_data_nino_summer_clim_10,\n",
    "        target_data_nino_summer_clim_11 = target_data_nino_summer_clim_11, target_data_nino_summer_clim_12 = target_data_nino_summer_clim_12,\n",
    "        target_data_nino_summer_clim_13 = target_data_nino_summer_clim_13, target_data_nino_summer_clim_14 = target_data_nino_summer_clim_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d3a0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(r'D:\\heat_wave\\atlantic\\Nino_spring_summer_autumn_winter_imshow\\heat_wave_autumn_clim.npz',\n",
    "       target_data_nino_autumn_clim_1 = target_data_nino_autumn_clim_1, target_data_nino_autumn_clim_2 = target_data_nino_autumn_clim_2,\n",
    "        target_data_nino_autumn_clim_3 = target_data_nino_autumn_clim_3, target_data_nino_autumn_clim_4 = target_data_nino_autumn_clim_4,\n",
    "        target_data_nino_autumn_clim_5 = target_data_nino_autumn_clim_5, target_data_nino_autumn_clim_6 = target_data_nino_autumn_clim_6,\n",
    "        target_data_nino_autumn_clim_7 = target_data_nino_autumn_clim_7, target_data_nino_autumn_clim_8 = target_data_nino_autumn_clim_8,\n",
    "        target_data_nino_autumn_clim_9 = target_data_nino_autumn_clim_9, target_data_nino_autumn_clim_10 = target_data_nino_autumn_clim_10,\n",
    "        target_data_nino_autumn_clim_11 = target_data_nino_autumn_clim_11, target_data_nino_autumn_clim_12 = target_data_nino_autumn_clim_12,\n",
    "        target_data_nino_autumn_clim_13 = target_data_nino_autumn_clim_13, target_data_nino_autumn_clim_14 = target_data_nino_autumn_clim_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "87ec33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(r'D:\\heat_wave\\atlantic\\Nino_spring_summer_autumn_winter_imshow\\heat_wave_winter_clim.npz',\n",
    "        target_data_nino_winter_clim_1 = target_data_nino_winter_clim_1, target_data_nino_winter_clim_2 = target_data_nino_winter_clim_2,\n",
    "        target_data_nino_winter_clim_3 = target_data_nino_winter_clim_3, target_data_nino_winter_clim_4 = target_data_nino_winter_clim_4,\n",
    "        target_data_nino_winter_clim_5 = target_data_nino_winter_clim_5, target_data_nino_winter_clim_6 = target_data_nino_winter_clim_6,\n",
    "        target_data_nino_winter_clim_7 = target_data_nino_winter_clim_7, target_data_nino_winter_clim_8 = target_data_nino_winter_clim_8,\n",
    "        target_data_nino_winter_clim_9 = target_data_nino_winter_clim_9, target_data_nino_winter_clim_10 = target_data_nino_winter_clim_10,\n",
    "        target_data_nino_winter_clim_11 = target_data_nino_winter_clim_11, target_data_nino_winter_clim_12 = target_data_nino_winter_clim_12,\n",
    "        target_data_nino_winter_clim_13 = target_data_nino_winter_clim_13, target_data_nino_winter_clim_14 = target_data_nino_winter_clim_14,\n",
    "        target_data_nino_winter_clim_15 = target_data_nino_winter_clim_15, target_data_nino_winter_clim_16 = target_data_nino_winter_clim_16,\n",
    "        target_data_nino_winter_clim_17 = target_data_nino_winter_clim_17, target_data_nino_winter_clim_18 = target_data_nino_winter_clim_18, \n",
    "        target_data_nino_winter_clim_19 = target_data_nino_winter_clim_19, target_data_nino_winter_clim_20 = target_data_nino_winter_clim_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45588f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
